## Master Method:
Master Method is a direct way to get the solution,this method works only for following type of recurrences or for recurrences that can be transformed to following type
```
T(n) = aT(n/b) + f(n) where a >= 1 and b > 1 
```
In the function to the analysis of a recursive algorithm, the constants and function take on the following significance:
- n is the size of the problem.
- a is the number of subproblems in the recursion.
- n/b is the size of each subproblem. (Here it is assumed that all subproblems are essentially the same size.)
- f (n) is the sum of the work done outside the recursive calls, which includes the sum of dividing the problem and the sum of combining the solutions to the subproblems.
- T(n) can't be a monotonic function. For e.g. T(n) = sin n
- f(n) can't be a polynomial. For e.g. T(n) = T(n/4) + 2n + n/7 
- It is not possible always bound the function according to the requirement, so we make three cases which will tell us what kind of bound we can apply on the function.

**There are following three cases:** 

 1. T(N) = O(N^logb(a)),  if k < logb(a)
 2. T(N) = O((N^k)*logN), if k = logb(a)
 3. T(N) = O(N^k),        if k > logb(a)

 Let's analyse the time complexity using the master theorem
 
 **Example 1**
 
 ```
 T(N) = T(N/2) + C
 ```
The above recurrence relation is of binary search,comparing this with master theorem, we get a = 1, b = 2 and k = 0 because f(N) = C = C(N^0)
Here logb(a) = k, so we can apply case 2 of the master theorem

T(n) = (N⁰*log(N)) = O(logN)

**Example 2**
```
T(N) = 2*T(N/2) + O(1)
```
The above recurrence relation is of finding min-max in an array through the divide and conquer approach
Comparing this with master theorem,a = 2, b = 2 and f(N) = 1,comparing left and right sides of f(N), we get k = 0,
**logb(a) = log2(2) = 1 > k** so, we can apply the case 1 of the master thorem 

T(N) = O(N^logb(a)) = O(N¹) = O(N)

**Example 3**
```
T(N) = 2T(N/2) + CN^2
```
Comparing this with master theorem, a = 2, b = 2 and f(N) = CN²
comparing left and right sides of f(n), we get k = 2,
**logb(a) = log2(2) = 1 < k**
So, we can apply the case 3 of the master thorem

T(N) = O(N^k)= O(N²)


**Why is recursion useful?**

- Recursion can reduce time complexity.
- Recursion adds clarity and reduces the time needed to write and debug code.
- Recursion can lead to more readable and efficient algorithm descriptions.
- Recursion is a useful way of defining things that have a repeated similar structural form like tree traversal.
