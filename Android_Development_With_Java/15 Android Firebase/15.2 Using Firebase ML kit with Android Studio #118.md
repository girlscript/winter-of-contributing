# Issue Name:Using Firebase ML kit with Android Studio
## GirlScript Winter Of Code'21
## OVERVIEW

### ML Kit particularities
ML Kit SDK is a rather new product from Google that was presented in 2018. ML Kit is a software development kit that makes it possible for developers to simplify the integration of machine learning models into their mobile apps.
ML Kit is still available in the beta version only. At the moment, there are 11 features with APIs available. By the way, only 5 features were available on Google I/O presentation in 2018, and today, this number is doubled. Features are the following:
##### Text recognition;
##### Face detection;
##### Barcode scanning;
##### Image labeling;
##### Object detection & tracking;
##### Landmark recognition;
##### Language identification;
##### Translation;
##### Smart reply;
##### AutoML model inference;
##### Custom model inference.
We will explore each feature and its API better a bit later, and now we will single out particularities and strong sides of ML Kit.


### Clear and easy-to-use
It is not a secret that the integration of AI-based algorithms into mobile apps is not an easy task, and it requires good skills and much time. For a start, developers need to learn some appropriate machine learning libraries like TensorFlow, Torch, PyBrain, Azure, and so on. Then, a neural network should be trained to implement all the necessary tasks. But it is not the end! Moreover, it is just the beginning. The next step is to build a machine learning model that will be not very heavy since it should run on mobile devices smoothly. And only when the model is built, developers may relax a bit. As you can see, this task is rather complicated even for experienced developers.
But the new ML Kit SDK allows developers to make everything faster and easier. Developers need to pass data to the required API and wait for the response from SDK. Google’s representatives assure that developers don’t need to be highly skilled in neural networks to implement their APIs. Everything developers need is to add several lines of codes, and a new app will get cool AI-based features.

### Custom models
It is an appropriate option for skilled developers. If existing ML Kit APIs don’t provide developers with the features they need, they can build their custom ML models. On Firebase website, there is an explanation of how developers can do it and benefit from their models.
ML Kit works with TensorFlow, and this is a machine learning library for iOS and Android operating systems. This library allows developers to download their model to Firebase console and bundle it with their product. If a built model is too heavy, developers can leave it in the cloud, and then arrange dynamical downloading to the app. It makes it possible to downsize the app, and users will download the app faster. Apart from this, updates of models are also dynamic, and it is an important thing. It means that the model will be updated, whereas the whole app won’t be updated.


### On-device and cloud APIs

Developers can choose on-device or cloud APIs, depending on their needs. If you don’t know what option is better, you should consider all the differences to make the right choice. Cloud APIs process data on the Google Cloud Platform, therefore object recognition is performed more precisely.
However, cloud models are larger than on-device models. On-device models require less space, they can function offline, and data processing is faster, but these models are not so accurate.
What’s more, there are some specific features both in offline and cloud mode. For example, text and landmark recognition, image labeling — these features work in the cloud. On-device APIs offer much more features like text recognition, face detection, barcode scanning, image labeling, object detection & tracking, language identification, translation, smart reply, AutoML model inference, Custom model inference.
Price also varies. Local APIs are free of charge. Firebase ML Kit uses Cloud Vision API, so cloud APIs and Cloud Vision APIs are provided at the same price. The more often you use APIs, the more you will need to pay, everything is simple. For example, up to 1000 uses per month, it’s free. Then each new 1000 uses will cost $1,50.
Also, one more important thing is privacy. According to Google’s statement, the user’s data isn’t stored in cloud APIs, and it is deleted once the processing is complete.

### Multi-platform
ML Kit SDK is a multi-platform, that is APIs can be used for iOS and Android apps. Thus, a new ML Kit may compete with CoreML from Apple and even beat it one day. However, today, CoreML has more advantages than ML Kit. For instance, CoreML uses TensorFlow, and it also accepts ONYX, Python tools, Apache MXNet.


Android apps that got ML features with ML Kit may run even on Android 4.0, so one of ML particularities is its capability to work on old Android versions. New versions like Android Oreo and Pie got better performance. Cloud models also use Standard Neural Network API for Android.
How other Firebase services interact with ML Kit
ML Kit SDK may function flawlessly with other Firebase services. Image labeling can be kept in Cloud Firestore. Or Google Analytics can be used to measure user engagement. Besides, A/B testing of custom ML models can be performed easily with the help of Remote Config and ML Kit.


## Firebase ML Kit - Your starter to the world of machine learning :)

Firebase ML Kit comes with the following machine learning APIs which are implemented and are ready to use in the application.

Text Recognition
Face Detection
Object Detection and Tracking
Image Labeling
AutoML vision Edge
Barcode Scanning
Landmark Recognition
Language Identification
On-device Translation
Smart Reply
This is an open-source project where you can find the implemented source code from the link provided below or in application https://github.com/shivamkumard107/FirebaseMLKit

You simply pass in data to the ML Kit library and it will give you the information you need. The on-device APIs process data quickly and will work even when there’s no network connection.

## How to run:

Head over the project  to https://firebase.google.com

Click on "Go to Console" , found on the top right of the screen. This will redirect you to a login page. Sign-in with your Google account.

Click "Create a Project". Follow the dialogs and create your project.

Your project will show up on the home page of your Firebase account. Select your project, and this will lead you to a Firebase console.

On the console page, you will find a "Get Started" display, under which you can click on the Android icon to link your Android project to your Firebase account.

Link for additional info: https://developer.android.com/studio/write/firebase
