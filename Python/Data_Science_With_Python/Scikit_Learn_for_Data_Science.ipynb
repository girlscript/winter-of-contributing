{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Scikit-Learn for Data Science",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DunoonaFPXup"
      },
      "source": [
        "# **Hello Folks! Welcome to this tutorial for Data Science with Machine Learning. This tutorial is for those who are beginners to Scikit-Learn and Machine Learning.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oasHFLX6fgEX"
      },
      "source": [
        "# **What is Scikit-Learn?**\n",
        "Scikit-Learn,often abbreviated as 'sklearn' is one of the top python libraries for Data Science.\n",
        "\n",
        "\n",
        "1.  It is a simple and efficient tool for data mining and data analysis.\n",
        "2.  It is a Python Library built on Numpy,Scipy and Matplotlib.\n",
        "3.  It is an open-source,commercially usable,BSD License library.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H8Cp19VjfgMu"
      },
      "source": [
        "# **What we can achieve using Scikit-Learn library?**\n",
        "The Scikit-Learn library features various Classfication,Regression,Clustering and many more algorithms.Refer the following points for more applications of the Scikit-Learn.\n",
        "\n",
        "\n",
        "*   **Classification:** Identifying which category an object belongs to. One of the applications of the Classification algorithm is Spam Detection.\n",
        "*   **Regression:** Predicting an attribute associated with an object. This algorithm can be used to predict the stock prices.\n",
        "\n",
        "\n",
        "*   **Clustering:** This refers to automatic grouping of similar objects into sets.One of the applications is customer segmentation.\n",
        "*   **Model Selection:** Comparing,Validating and choosing parameters and models.One of the applications can be improving model efficiency via parameter tuning.\n",
        "\n",
        "\n",
        "*   **Dimensionality Reduction:** Reducing the number of random variables to consider.This feature can be used to increase the model efficiency.\n",
        "*   **Pre-Processing:** Feature extraction and normalization.The application can be transforming input data such as text for use with machine learning alogorithms.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ybTzkB1sfgTQ"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I8k5-m_Ufgdv"
      },
      "source": [
        "# **Importing Required packages**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FK6-m7ImrqM8"
      },
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn import svm\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "%matplotlib inline"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I559IqyFwQzJ"
      },
      "source": [
        "***After importing the required packages,we will now move on to loading the dataset.***\n",
        "In this analysis,we will use the dataset 'winequality-red.csv' ; which I got from Kaggle."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B4qydYJErqT2"
      },
      "source": [
        "redwine = pd.read_csv('winequality-red.csv')"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "MltLHPAJx875",
        "outputId": "c0669b16-4f15-4a51-c339-0318ff58d269"
      },
      "source": [
        "redwine.head()"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fixed acidity</th>\n",
              "      <th>volatile acidity</th>\n",
              "      <th>citric acid</th>\n",
              "      <th>residual sugar</th>\n",
              "      <th>chlorides</th>\n",
              "      <th>free sulfur dioxide</th>\n",
              "      <th>total sulfur dioxide</th>\n",
              "      <th>density</th>\n",
              "      <th>pH</th>\n",
              "      <th>sulphates</th>\n",
              "      <th>alcohol</th>\n",
              "      <th>quality</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7.4</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.076</td>\n",
              "      <td>11.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>0.9978</td>\n",
              "      <td>3.51</td>\n",
              "      <td>0.56</td>\n",
              "      <td>9.4</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7.8</td>\n",
              "      <td>0.88</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2.6</td>\n",
              "      <td>0.098</td>\n",
              "      <td>25.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>0.9968</td>\n",
              "      <td>3.20</td>\n",
              "      <td>0.68</td>\n",
              "      <td>9.8</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7.8</td>\n",
              "      <td>0.76</td>\n",
              "      <td>0.04</td>\n",
              "      <td>2.3</td>\n",
              "      <td>0.092</td>\n",
              "      <td>15.0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>0.9970</td>\n",
              "      <td>3.26</td>\n",
              "      <td>0.65</td>\n",
              "      <td>9.8</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.2</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.56</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.075</td>\n",
              "      <td>17.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>0.9980</td>\n",
              "      <td>3.16</td>\n",
              "      <td>0.58</td>\n",
              "      <td>9.8</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7.4</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.076</td>\n",
              "      <td>11.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>0.9978</td>\n",
              "      <td>3.51</td>\n",
              "      <td>0.56</td>\n",
              "      <td>9.4</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   fixed acidity  volatile acidity  citric acid  ...  sulphates  alcohol  quality\n",
              "0            7.4              0.70         0.00  ...       0.56      9.4        5\n",
              "1            7.8              0.88         0.00  ...       0.68      9.8        5\n",
              "2            7.8              0.76         0.04  ...       0.65      9.8        5\n",
              "3           11.2              0.28         0.56  ...       0.58      9.8        6\n",
              "4            7.4              0.70         0.00  ...       0.56      9.4        5\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SA-utiUWyUf8"
      },
      "source": [
        "**The .head() function will display the top 5 rows by default. If you wish to print the first 10 rows,add 10 in the parenthesis.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nY_UUh6crqYb",
        "outputId": "8b94bba1-8510-449f-9d39-e7c139195258"
      },
      "source": [
        "redwine.info()"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1599 entries, 0 to 1598\n",
            "Data columns (total 12 columns):\n",
            " #   Column                Non-Null Count  Dtype  \n",
            "---  ------                --------------  -----  \n",
            " 0   fixed acidity         1599 non-null   float64\n",
            " 1   volatile acidity      1599 non-null   float64\n",
            " 2   citric acid           1599 non-null   float64\n",
            " 3   residual sugar        1599 non-null   float64\n",
            " 4   chlorides             1599 non-null   float64\n",
            " 5   free sulfur dioxide   1599 non-null   float64\n",
            " 6   total sulfur dioxide  1599 non-null   float64\n",
            " 7   density               1599 non-null   float64\n",
            " 8   pH                    1599 non-null   float64\n",
            " 9   sulphates             1599 non-null   float64\n",
            " 10  alcohol               1599 non-null   float64\n",
            " 11  quality               1599 non-null   int64  \n",
            "dtypes: float64(11), int64(1)\n",
            "memory usage: 150.0 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DfG5zF0MzMah"
      },
      "source": [
        "**The .info() function will give a concise summary of the dataframe.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fr1mkujDzUzl",
        "outputId": "0d498c8c-b485-40ec-a74b-3d10590d5338"
      },
      "source": [
        "redwine.isnull().sum()"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "fixed acidity           0\n",
              "volatile acidity        0\n",
              "citric acid             0\n",
              "residual sugar          0\n",
              "chlorides               0\n",
              "free sulfur dioxide     0\n",
              "total sulfur dioxide    0\n",
              "density                 0\n",
              "pH                      0\n",
              "sulphates               0\n",
              "alcohol                 0\n",
              "quality                 0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37vkOVxG0FEo"
      },
      "source": [
        "**This function will tell us the number of null values in the respective dataframe.As we can see,there are no null values in the dataframe,hence 0 is returned.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DWTFc3Dd1FOw"
      },
      "source": [
        "# **Preprocessing Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_xVbKWJzU2E"
      },
      "source": [
        "bins = (2, 6.5, 8)\n",
        "group_names = ['bad' , 'good']\n",
        "redwine['quality'] = pd.cut(redwine['quality'], bins =  bins,labels = group_names)"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xsVxx4Rm2-wY"
      },
      "source": [
        "**By using the above lines of code,we are going to separate the wines into two labels of quality.The wines whose quality ranges from 2 to 6.5 would be labelled as \"bad\" where wines ranging from 6.5 to 8 will be labelled as \"good.\"**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAOHm4fKzU4T"
      },
      "source": [
        "label_quality = LabelEncoder() #The LabelEncoder() funtion is a part of the Scikit-Learn library."
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8NfzFlNzU7J"
      },
      "source": [
        "redwine['quality'] = label_quality.fit_transform(redwine['quality'])"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kgSJGQJ5-cMR"
      },
      "source": [
        "**This fit_transform() method is basically the combination of fit method and transform method.This method performs fit and transform on the input data at a single time and converts the data points.** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "id": "Qy7KRpe84jGM",
        "outputId": "10ad965d-9217-4655-92b1-3c70dd4f8986"
      },
      "source": [
        "redwine.head(10)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fixed acidity</th>\n",
              "      <th>volatile acidity</th>\n",
              "      <th>citric acid</th>\n",
              "      <th>residual sugar</th>\n",
              "      <th>chlorides</th>\n",
              "      <th>free sulfur dioxide</th>\n",
              "      <th>total sulfur dioxide</th>\n",
              "      <th>density</th>\n",
              "      <th>pH</th>\n",
              "      <th>sulphates</th>\n",
              "      <th>alcohol</th>\n",
              "      <th>quality</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7.4</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.076</td>\n",
              "      <td>11.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>0.9978</td>\n",
              "      <td>3.51</td>\n",
              "      <td>0.56</td>\n",
              "      <td>9.4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7.8</td>\n",
              "      <td>0.88</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2.6</td>\n",
              "      <td>0.098</td>\n",
              "      <td>25.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>0.9968</td>\n",
              "      <td>3.20</td>\n",
              "      <td>0.68</td>\n",
              "      <td>9.8</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7.8</td>\n",
              "      <td>0.76</td>\n",
              "      <td>0.04</td>\n",
              "      <td>2.3</td>\n",
              "      <td>0.092</td>\n",
              "      <td>15.0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>0.9970</td>\n",
              "      <td>3.26</td>\n",
              "      <td>0.65</td>\n",
              "      <td>9.8</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.2</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.56</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.075</td>\n",
              "      <td>17.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>0.9980</td>\n",
              "      <td>3.16</td>\n",
              "      <td>0.58</td>\n",
              "      <td>9.8</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7.4</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.076</td>\n",
              "      <td>11.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>0.9978</td>\n",
              "      <td>3.51</td>\n",
              "      <td>0.56</td>\n",
              "      <td>9.4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>7.4</td>\n",
              "      <td>0.66</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.8</td>\n",
              "      <td>0.075</td>\n",
              "      <td>13.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>0.9978</td>\n",
              "      <td>3.51</td>\n",
              "      <td>0.56</td>\n",
              "      <td>9.4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7.9</td>\n",
              "      <td>0.60</td>\n",
              "      <td>0.06</td>\n",
              "      <td>1.6</td>\n",
              "      <td>0.069</td>\n",
              "      <td>15.0</td>\n",
              "      <td>59.0</td>\n",
              "      <td>0.9964</td>\n",
              "      <td>3.30</td>\n",
              "      <td>0.46</td>\n",
              "      <td>9.4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7.3</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.2</td>\n",
              "      <td>0.065</td>\n",
              "      <td>15.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>0.9946</td>\n",
              "      <td>3.39</td>\n",
              "      <td>0.47</td>\n",
              "      <td>10.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>7.8</td>\n",
              "      <td>0.58</td>\n",
              "      <td>0.02</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.073</td>\n",
              "      <td>9.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>0.9968</td>\n",
              "      <td>3.36</td>\n",
              "      <td>0.57</td>\n",
              "      <td>9.5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>7.5</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.36</td>\n",
              "      <td>6.1</td>\n",
              "      <td>0.071</td>\n",
              "      <td>17.0</td>\n",
              "      <td>102.0</td>\n",
              "      <td>0.9978</td>\n",
              "      <td>3.35</td>\n",
              "      <td>0.80</td>\n",
              "      <td>10.5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   fixed acidity  volatile acidity  citric acid  ...  sulphates  alcohol  quality\n",
              "0            7.4              0.70         0.00  ...       0.56      9.4        0\n",
              "1            7.8              0.88         0.00  ...       0.68      9.8        0\n",
              "2            7.8              0.76         0.04  ...       0.65      9.8        0\n",
              "3           11.2              0.28         0.56  ...       0.58      9.8        0\n",
              "4            7.4              0.70         0.00  ...       0.56      9.4        0\n",
              "5            7.4              0.66         0.00  ...       0.56      9.4        0\n",
              "6            7.9              0.60         0.06  ...       0.46      9.4        0\n",
              "7            7.3              0.65         0.00  ...       0.47     10.0        1\n",
              "8            7.8              0.58         0.02  ...       0.57      9.5        1\n",
              "9            7.5              0.50         0.36  ...       0.80     10.5        0\n",
              "\n",
              "[10 rows x 12 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0eXuR4oQ-9SM"
      },
      "source": [
        "**After running the code above,we can observe the wines have been labelled as good(1) and bad(0) in terms of quality.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oTKIUFXA4jI5",
        "outputId": "3de64c12-77b1-4bf2-ed75-86ec62dc0db2"
      },
      "source": [
        "redwine['quality'].value_counts()"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    1382\n",
              "1     217\n",
              "Name: quality, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHzHrm_y_wl4"
      },
      "source": [
        "**After labelling and segregating the wines as good and bad we can see the actual number of wines which are good and bad in terms of quality.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "HgQnwYmX4jKt",
        "outputId": "05d4272a-d11c-413d-9c58-6391cce3bde4"
      },
      "source": [
        "sns.countplot(redwine['quality'])"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f3980e25950>"
            ]
          },
          "metadata": {},
          "execution_count": 73
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qg2xWFCwAOPA"
      },
      "source": [
        "**We can also depict the number of good and bad wines graphically.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWoRceUrA_I4"
      },
      "source": [
        "# **Separating the dataset as response variable and feature variable:**\n",
        "\n",
        "\n",
        "*   Response Variable: It is a variation depends on other variables. It is the subject of change within an experiment.\n",
        "*   Feature Variable: A feature variable is a measurable property of the object youâ€™re trying to analyze. In datasets, features appear as columns.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XvAspnQp4jNP"
      },
      "source": [
        "X = redwine.drop('quality' , axis = 1)\n",
        "y = redwine['quality']"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8TlX7rdCpHi"
      },
      "source": [
        "# **Training and Test Splitting of data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nwb8TFQr4jPQ"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
        "#The train_test_split() function is a part of the Scikit-Learn library."
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q1wX4A4aPC2_"
      },
      "source": [
        "# **Applying Standard Scaling to get optimized result**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7GBF7sOD4jRi"
      },
      "source": [
        "sc = StandardScaler()   #The StandardScaler() funtion is a part of the Scikit-Learn library.\n",
        "                        #StandardScaler removes the mean and scales each feature/variable to unit variance.\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G6LtMjCw4jT5",
        "outputId": "8ac31940-c36d-4f59-e9af-81ae42075ec2"
      },
      "source": [
        "X_train[:10]"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.21833164,  0.88971201,  0.19209222,  0.30972563, -0.04964208,\n",
              "         0.69100692,  1.04293362,  1.84669643,  1.09349989,  0.45822284,\n",
              "         1.12317723],\n",
              "       [-1.29016623, -1.78878251,  0.65275338, -0.80507963, -0.45521361,\n",
              "         2.38847304,  3.59387025, -3.00449133, -0.40043872, -0.40119696,\n",
              "         1.40827174],\n",
              "       [ 1.49475291, -0.78434707,  1.01104539, -0.52637831,  0.59927236,\n",
              "        -0.95796016, -0.99174203,  0.76865471, -0.07566946,  0.51551749,\n",
              "        -0.58738978],\n",
              "       [ 0.27635078,  0.86181102, -0.06383064, -0.66572897, -0.00908493,\n",
              "         0.01202048, -0.71842739,  0.08948842,  0.05423824, -1.08873281,\n",
              "        -0.96751578],\n",
              "       [ 0.04427419,  2.81487994, -0.62686095,  2.39998549, -0.31326357,\n",
              "        -0.47296984,  0.2229897 ,  1.1998714 ,  0.37900751, -0.9741435 ,\n",
              "        -0.49235828],\n",
              "       [-0.07176411, -0.78434707,  1.11341454, -0.17800167,  0.21397941,\n",
              "         3.01896045,  2.62208486,  0.60694845,  0.44396136,  1.89058918,\n",
              "        -0.58738978],\n",
              "       [-1.17412793,  0.10848444, -0.62686095, -0.52637831, -0.23214927,\n",
              "         0.98200112, -0.35400787, -1.95879086,  0.05423824,  0.91658007,\n",
              "         1.12317723],\n",
              "       [-0.1878024 , -0.17052541,  0.60156881,  0.03102432, -0.13075639,\n",
              "        -0.37597178, -0.01995665,  0.93036097,  0.76873063, -0.229313  ,\n",
              "         0.26789373],\n",
              "       [-0.07176411,  0.61070216, -0.01264607, -0.38702766,  0.13286511,\n",
              "        -1.05495822,  0.92146044,  0.37516948, -1.17988496, -0.229313  ,\n",
              "        -1.25261029],\n",
              "       [ 1.8428678 , -1.95618842,  1.21578369,  1.00647892,  0.31537229,\n",
              "        -1.15195628, -0.71842739,  1.52328391, -0.20557717,  1.77599987,\n",
              "        -0.30229528]])"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dr__kQKcQ-1s"
      },
      "source": [
        "**From the above lines of code,we can observe that our variables are now much more uniform and they have scaled themselves to the same scale.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zYRwGcaIGyAF"
      },
      "source": [
        "# **The training and testing of data is now complete.We will use the following machine learning algorithms:**\n",
        "\n",
        "\n",
        "*   Random Forest Classifier\n",
        "*   SVM Classifier\n",
        "*   Logistic Regression\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "**We will also form a Neural Network using the MLP Classifier**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EpwpzAwUcY5c"
      },
      "source": [
        "# **Random Forest Classifier**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMqNRyA64jWU"
      },
      "source": [
        "rfc = RandomForestClassifier(n_estimators=200)\n",
        "rfc.fit(X_train, y_train)\n",
        "rfc_pred = rfc.predict(X_test)"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ji3O4USRRUhe",
        "outputId": "1282923f-4dad-41a5-d2f8-8fd12c1c75df"
      },
      "source": [
        "pred_rfc[:20]"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rry7mQvyepEW"
      },
      "source": [
        "**After executing the above lines of code,we can observe that out of 20 wines,17 are classified as bad and 3 as good.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6Q6tlPofEyf"
      },
      "source": [
        "# **Let's see how well our model has performed:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S93jKFW2RUkF",
        "outputId": "b56fdf16-042b-4aed-ca84-77fce40b0a4c"
      },
      "source": [
        "print(classification_report(y_test, rfc_pred)) \n",
        "print(confusion_matrix(y_test, rfc_pred)) \n",
        "#The classification_report and confusion_matrix function is a part of the Scikit-Learn Library."
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.96      0.94       273\n",
            "           1       0.71      0.51      0.59        47\n",
            "\n",
            "    accuracy                           0.90       320\n",
            "   macro avg       0.81      0.74      0.77       320\n",
            "weighted avg       0.89      0.90      0.89       320\n",
            "\n",
            "[[263  10]\n",
            " [ 23  24]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05cKDDDewZuN"
      },
      "source": [
        "**By using the confusion matrix,we can determine how well our model works and how accurate our model is. As you can observe from the confusion matrix,the model can determine that 264 wines are of bad quality correctly. Whereas 7 of the bad quality wines were mislabelled. The same applies to good quality wines.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nFRqK7qoy6yh"
      },
      "source": [
        "# **SVM Classifier**\n",
        "**(Support Vector Model)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5iV9x3LmRUmk"
      },
      "source": [
        "svm=svm.SVC()\n",
        "svm.fit(X_train, y_train)\n",
        "svm_pred = clf.predict(X_test)"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rTtAD7e62bJw"
      },
      "source": [
        "# **Let's see how well our model has performed:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dnZsDdUARUpQ",
        "outputId": "7b33c34c-4db4-4f7a-9456-1b03fa837e3e"
      },
      "source": [
        "print(classification_report(y_test, svm_pred)) \n",
        "print(confusion_matrix(y_test, svm_pred)) \n"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.98      0.93       273\n",
            "           1       0.71      0.26      0.37        47\n",
            "\n",
            "    accuracy                           0.88       320\n",
            "   macro avg       0.80      0.62      0.65       320\n",
            "weighted avg       0.86      0.88      0.85       320\n",
            "\n",
            "[[268   5]\n",
            " [ 35  12]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kbonZMmJ3iRP"
      },
      "source": [
        "**The SVM Classifier tends to work better with smaller numbers**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDwCDg2KNQUY"
      },
      "source": [
        "# **Logistic Regression**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HleLmVA1Nbgc"
      },
      "source": [
        "lr = LogisticRegression()\n",
        "lr.fit(X_train, y_train)\n",
        "lr_pred = lr.predict(X_test)"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5GtnAYVLNujI"
      },
      "source": [
        "# **Let's see how well our model has performed:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JOekGXLhNbmn",
        "outputId": "b0477662-39f7-4b84-8da6-77a26a37d8cb"
      },
      "source": [
        "print(classification_report(y_test, lr_pred)) \n",
        "print(confusion_matrix(y_test, lr_pred)) "
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.97      0.92       273\n",
            "           1       0.59      0.28      0.38        47\n",
            "\n",
            "    accuracy                           0.87       320\n",
            "   macro avg       0.74      0.62      0.65       320\n",
            "weighted avg       0.84      0.87      0.84       320\n",
            "\n",
            "[[264   9]\n",
            " [ 34  13]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3Z44lz43yZl"
      },
      "source": [
        "# **Neural Networks**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zp4EW7v-RUrT",
        "outputId": "cc8bccb5-9d6e-48f3-9b7e-5e5a49fa13cc"
      },
      "source": [
        "mlpc=MLPClassifier(hidden_layer_sizes=(11,11,11),max_iter=500)\n",
        "mlpc.fit(X_train, y_train)\n",
        "mlpc_pred = mlpc.predict(X_test)"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TiuJ18036I4M"
      },
      "source": [
        "# **Let's see how well our model has performed:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Jg32wZT3wkL",
        "outputId": "e61351a0-d688-4805-c271-544a61e318c9"
      },
      "source": [
        "print(classification_report(y_test, mlpc_pred)) \n",
        "print(confusion_matrix(y_test, mlpc_pred)) "
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.95      0.93       273\n",
            "           1       0.63      0.55      0.59        47\n",
            "\n",
            "    accuracy                           0.89       320\n",
            "   macro avg       0.78      0.75      0.76       320\n",
            "weighted avg       0.88      0.89      0.88       320\n",
            "\n",
            "[[258  15]\n",
            " [ 21  26]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "toNiYBNwPV0x"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MTYBQe-7-a2"
      },
      "source": [
        "# **Determine the accuracy of our best model,which is RFC:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZOFxyu6h3wnF",
        "outputId": "06be1988-71ec-4aab-b42a-4eec5666d03d"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "cm = accuracy_score(y_test, pred_rfc)\n",
        "cm"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.909375"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "id": "aG9oUhJf3wqv",
        "outputId": "0be5c585-2fa2-4982-def7-39d95b3b6add"
      },
      "source": [
        "redwine.head(10)"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fixed acidity</th>\n",
              "      <th>volatile acidity</th>\n",
              "      <th>citric acid</th>\n",
              "      <th>residual sugar</th>\n",
              "      <th>chlorides</th>\n",
              "      <th>free sulfur dioxide</th>\n",
              "      <th>total sulfur dioxide</th>\n",
              "      <th>density</th>\n",
              "      <th>pH</th>\n",
              "      <th>sulphates</th>\n",
              "      <th>alcohol</th>\n",
              "      <th>quality</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7.4</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.076</td>\n",
              "      <td>11.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>0.9978</td>\n",
              "      <td>3.51</td>\n",
              "      <td>0.56</td>\n",
              "      <td>9.4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7.8</td>\n",
              "      <td>0.88</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2.6</td>\n",
              "      <td>0.098</td>\n",
              "      <td>25.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>0.9968</td>\n",
              "      <td>3.20</td>\n",
              "      <td>0.68</td>\n",
              "      <td>9.8</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7.8</td>\n",
              "      <td>0.76</td>\n",
              "      <td>0.04</td>\n",
              "      <td>2.3</td>\n",
              "      <td>0.092</td>\n",
              "      <td>15.0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>0.9970</td>\n",
              "      <td>3.26</td>\n",
              "      <td>0.65</td>\n",
              "      <td>9.8</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.2</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.56</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.075</td>\n",
              "      <td>17.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>0.9980</td>\n",
              "      <td>3.16</td>\n",
              "      <td>0.58</td>\n",
              "      <td>9.8</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7.4</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.076</td>\n",
              "      <td>11.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>0.9978</td>\n",
              "      <td>3.51</td>\n",
              "      <td>0.56</td>\n",
              "      <td>9.4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>7.4</td>\n",
              "      <td>0.66</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.8</td>\n",
              "      <td>0.075</td>\n",
              "      <td>13.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>0.9978</td>\n",
              "      <td>3.51</td>\n",
              "      <td>0.56</td>\n",
              "      <td>9.4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7.9</td>\n",
              "      <td>0.60</td>\n",
              "      <td>0.06</td>\n",
              "      <td>1.6</td>\n",
              "      <td>0.069</td>\n",
              "      <td>15.0</td>\n",
              "      <td>59.0</td>\n",
              "      <td>0.9964</td>\n",
              "      <td>3.30</td>\n",
              "      <td>0.46</td>\n",
              "      <td>9.4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7.3</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.2</td>\n",
              "      <td>0.065</td>\n",
              "      <td>15.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>0.9946</td>\n",
              "      <td>3.39</td>\n",
              "      <td>0.47</td>\n",
              "      <td>10.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>7.8</td>\n",
              "      <td>0.58</td>\n",
              "      <td>0.02</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.073</td>\n",
              "      <td>9.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>0.9968</td>\n",
              "      <td>3.36</td>\n",
              "      <td>0.57</td>\n",
              "      <td>9.5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>7.5</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.36</td>\n",
              "      <td>6.1</td>\n",
              "      <td>0.071</td>\n",
              "      <td>17.0</td>\n",
              "      <td>102.0</td>\n",
              "      <td>0.9978</td>\n",
              "      <td>3.35</td>\n",
              "      <td>0.80</td>\n",
              "      <td>10.5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   fixed acidity  volatile acidity  citric acid  ...  sulphates  alcohol  quality\n",
              "0            7.4              0.70         0.00  ...       0.56      9.4        0\n",
              "1            7.8              0.88         0.00  ...       0.68      9.8        0\n",
              "2            7.8              0.76         0.04  ...       0.65      9.8        0\n",
              "3           11.2              0.28         0.56  ...       0.58      9.8        0\n",
              "4            7.4              0.70         0.00  ...       0.56      9.4        0\n",
              "5            7.4              0.66         0.00  ...       0.56      9.4        0\n",
              "6            7.9              0.60         0.06  ...       0.46      9.4        0\n",
              "7            7.3              0.65         0.00  ...       0.47     10.0        1\n",
              "8            7.8              0.58         0.02  ...       0.57      9.5        1\n",
              "9            7.5              0.50         0.36  ...       0.80     10.5        0\n",
              "\n",
              "[10 rows x 12 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wDpIE1EGPd_D"
      },
      "source": [
        "# **That's it from my side folks! I hope that you understood the purpose of Scikit Learn and the basic functions required to perform Data Analysis on a dataset.**"
      ]
    }
  ]
}