{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Q Learning"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Q-Learning Example\n",
    "For this example we will use the Q-Learning algorithm to train an agent to navigate a popular enviornment from the [Open AI Gym](https://gym.openai.com/). The Open AI Gym was developed so programmers could practice machine learning using unique enviornments. Intersting fact, Elon Musk is one of the founders of OpenAI!\n",
    "\n",
    "Let's start by looking at what Open AI Gym is. "
   ],
   "metadata": {
    "id": "rwIl0sJgmu4D"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import gym   # all you have to do to import and use open ai gym!"
   ],
   "outputs": [],
   "metadata": {
    "id": "rSETF0zqokYr"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Once you import gym you can load an enviornment using the line ```gym.make(\"enviornment\")```."
   ],
   "metadata": {
    "id": "8cH3AmCzotO1"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "env = gym.make('FrozenLake-v1')  # we are going to use the FrozenLake enviornment"
   ],
   "outputs": [],
   "metadata": {
    "id": "UKN1ScBco3dp"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "There are a few other commands that can be used to interact and get information about the enviornment."
   ],
   "metadata": {
    "id": "3SvSlmVwo8cY"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "print(env.observation_space.n)   # get number of states\r\n",
    "print(env.action_space.n)   # get number of actions"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "16\n",
      "4\n"
     ]
    }
   ],
   "metadata": {
    "id": "FF3icIeapFct"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "env.reset()  # reset enviornment to default state"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {
    "id": "lc9cwp03pQVn"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "action = env.action_space.sample()  # get a random action "
   ],
   "outputs": [],
   "metadata": {
    "id": "sngyjPDapUt7"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "new_state, reward, done, info = env.step(action)  # take action, notice it returns information about the action"
   ],
   "outputs": [],
   "metadata": {
    "id": "HeEfi8xypXya"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "env.render()   # render the GUI for the enviornment "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  (Left)\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n"
     ]
    }
   ],
   "metadata": {
    "id": "_1W3D81ipdaS"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Frozen Lake Enviornment\n",
    "Now that we have a basic understanding of how the gym enviornment works it's time to discuss the specific problem we will be solving.\n",
    "\n",
    "The enviornment we loaded above ```FrozenLake-v1``` is one of the simplest enviornments in Open AI Gym. The goal of the agent is to navigate a frozen lake and find the Goal without falling through the ice (render the enviornment above to see an example).\n",
    "\n",
    "There are:\n",
    "- 16 states (one for each square) \n",
    "- 4 possible actions (LEFT, RIGHT, DOWN, UP)\n",
    "- 4 different types of blocks (F: frozen, H: hole, S: start, G: goal)\n",
    "\n"
   ],
   "metadata": {
    "id": "vmW6HAbQp01f"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Building the Q-Table\n",
    "The first thing we need to do is build an empty Q-Table that we can use to store and update our values."
   ],
   "metadata": {
    "id": "YlWoK75ZrK2b"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "env = gym.make('FrozenLake-v1')\n",
    "STATES = env.observation_space.n\n",
    "ACTIONS = env.action_space.n"
   ],
   "outputs": [],
   "metadata": {
    "id": "r767K4s0rR2p"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "Q = np.zeros((STATES, ACTIONS))  # create a matrix with all 0 values \n",
    "Q"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.]])"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {
    "id": "UAzMWGatrVIk"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Constants\n",
    "As we discussed we need to define some constants that will be used to update our Q-Table and tell our agent when to stop training."
   ],
   "metadata": {
    "id": "vc_h8tLSrpmc"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "EPISODES = 2000 # how many times to run the enviornment from the beginning\n",
    "MAX_STEPS = 100  # max number of steps allowed for each run of enviornment\n",
    "\n",
    "LEARNING_RATE = 0.81  # learning rate\n",
    "GAMMA = 0.96"
   ],
   "outputs": [],
   "metadata": {
    "id": "-FQapdnnr6P1"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Picking an Action\n",
    "Remember that we can pick an action using one of two methods:\n",
    "1. Randomly picking a valid action\n",
    "2. Using the current Q-Table to find the best action.\n",
    "\n",
    "Here we will define a new value $\\epsilon$ that will tell us the probabillity of selecting a random action. This value will start off very high and slowly decrease as the agent learns more about the enviornment."
   ],
   "metadata": {
    "id": "NxrAj91rsMfm"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "epsilon = 0.9  # start with a 90% chance of picking a random action\n",
    "\n",
    "# code to pick action\n",
    "if np.random.uniform(0, 1) < epsilon:  # we will check if a randomly selected value is less than epsilon.\n",
    "    action = env.action_space.sample()  # take random action\n",
    "else:\n",
    "    action = np.argmax(Q[state, :])  # use Q table to pick best action based on current values"
   ],
   "outputs": [],
   "metadata": {
    "id": "YUAQVyX0sWDb"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Updating Q Values\n",
    "The code below implements the formula discussed above."
   ],
   "metadata": {
    "id": "5n-i0B7Atige"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "Q[state, action] = Q[state, action] + LEARNING_RATE * (reward + GAMMA * np.max(Q[new_state, :]) - Q[state, action])"
   ],
   "outputs": [],
   "metadata": {
    "id": "9r7R1W6Qtnh8"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Putting it Together\n",
    "Now that we know how to do some basic things we can combine these together to create our Q-Learning algorithm,"
   ],
   "metadata": {
    "id": "__afaD62uh8G"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "env = gym.make('FrozenLake-v1')\n",
    "STATES = env.observation_space.n\n",
    "ACTIONS = env.action_space.n\n",
    "\n",
    "Q = np.zeros((STATES, ACTIONS))\n",
    "\n",
    "EPISODES = 1500 # how many times to run the enviornment from the beginning\n",
    "MAX_STEPS = 100  # max number of steps allowed for each run of enviornment\n",
    "\n",
    "LEARNING_RATE = 0.81  # learning rate\n",
    "GAMMA = 0.96\n",
    "\n",
    "RENDER = False # if you want to see training set to true\n",
    "\n",
    "epsilon = 0.9\n"
   ],
   "outputs": [],
   "metadata": {
    "id": "AGiYCiNuutHz"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "rewards = []\n",
    "for episode in range(EPISODES):\n",
    "\n",
    "  state = env.reset()\n",
    "  for _ in range(MAX_STEPS):\n",
    "    \n",
    "    if RENDER:\n",
    "      env.render()\n",
    "\n",
    "    if np.random.uniform(0, 1) < epsilon:\n",
    "      action = env.action_space.sample()  \n",
    "    else:\n",
    "      action = np.argmax(Q[state, :])\n",
    "\n",
    "    next_state, reward, done, _ = env.step(action)\n",
    "\n",
    "    Q[state, action] = Q[state, action] + LEARNING_RATE * (reward + GAMMA * np.max(Q[next_state, :]) - Q[state, action])\n",
    "\n",
    "    state = next_state\n",
    "\n",
    "    if done: \n",
    "      rewards.append(reward)\n",
    "      epsilon -= 0.001\n",
    "      break  # reached goal\n",
    "\n",
    "print(Q)\n",
    "print(f\"Average reward: {sum(rewards)/len(rewards)}:\")\n",
    "# and now we can see our Q values!"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[4.55130020e-01 9.69888058e-03 9.58336349e-03 9.65889939e-03]\n",
      " [3.41806678e-03 3.59269419e-03 2.09486884e-03 7.04298681e-03]\n",
      " [5.66525206e-03 3.85760183e-03 2.62019565e-02 5.92296634e-03]\n",
      " [1.42245017e-03 1.74351386e-03 2.12434213e-03 1.37885687e-02]\n",
      " [4.66002437e-01 8.01398571e-03 6.54275283e-03 1.05452300e-02]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [8.05813689e-05 2.82703960e-05 2.84181100e-01 2.18138370e-04]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [1.03175406e-02 3.30749288e-03 2.22466487e-03 5.19900614e-01]\n",
      " [3.36504640e-03 5.99904708e-01 2.99999892e-03 2.21411837e-03]\n",
      " [8.69001263e-01 1.56766898e-04 1.63156354e-04 6.93030778e-04]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [1.26716469e-01 8.31278200e-02 6.89009887e-01 3.31004240e-02]\n",
      " [1.88659710e-01 1.46994555e-01 9.77193330e-01 1.69968889e-01]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n",
      "Average reward: 0.328:\n"
     ]
    }
   ],
   "metadata": {
    "id": "jFRtn5dUu5ZI"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "# we can plot the training progress and see how the agent improved\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def get_average(values):\n",
    "  return sum(values)/len(values)\n",
    "\n",
    "avg_rewards = []\n",
    "for i in range(0, len(rewards), 100):\n",
    "  avg_rewards.append(get_average(rewards[i:i+100])) \n",
    "\n",
    "plt.plot(avg_rewards)\n",
    "plt.ylabel('average reward')\n",
    "plt.xlabel('episodes (100\\'s)')\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {
    "id": "Zo-tNznd65US"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Sources\n",
    "1. Violante, Andre. “Simple Reinforcement Learning: Q-Learning.” Medium, Towards Data Science, 1 July 2019, https://towardsdatascience.com/simple-reinforcement-learning-q-learning-fcddc4b6fe56.\n",
    "\n",
    "2. Openai. “Openai/Gym.” GitHub, https://github.com/openai/gym/wiki/FrozenLake-v0."
   ],
   "metadata": {
    "id": "gy4YH2m9s1ww"
   }
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Reinforcement Learning.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}