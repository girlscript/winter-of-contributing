{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93e64129",
   "metadata": {},
   "source": [
    "In the following example, Age is the Target variable whereas LikesExercising, GotoGym, DrivesCar are independent variables. As in this example, the target variable is continuous, GradientBoostingRegressor is used here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31e0c026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.preprocessing import LabelEncoder \n",
    "# Let us create the Data-Frame for above \n",
    "X=pd.DataFrame({'LikesExercising':[False,False,False,True,False,True,True,True,True],\n",
    "                'GotoGym':[True,True,True,True,True,False,True,False,False],\n",
    "                 'DrivesCar':[True,False,False,True,True,False,True,False,True]})\n",
    "Y=pd.Series(name='Age',data=[14,15,16,26,36,50,69,72,74])\n",
    "# Let us encode true and false to number value 0 and 1\n",
    "LE=LabelEncoder()\n",
    "X['LikesExercising']=LE.fit_transform(X['LikesExercising'])\n",
    "X['GotoGym']=LE.fit_transform(X['GotoGym'])\n",
    "X['DrivesCar']=LE.fit_transform(X['DrivesCar'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e802deec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will now see the effect of different numbers of estimators on MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2b007ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for two estimators : 432.48205555555546\n"
     ]
    }
   ],
   "source": [
    "# 1) Let us now use  GradientBoostingRegressor with 2 estimators to train the model and to predict the age for the same inputs. \n",
    "GB=GradientBoostingRegressor(n_estimators=2)\n",
    "GB.fit(X,Y)\n",
    "Y_predict=GB.predict(X) #ages predicted by model with 2 estimators \n",
    "Y_predict\n",
    "# Output\n",
    "#Y_predict=[38.23 , 36.425, 36.425, 42.505, 38.23 , 45.07 , 42.505, 45.07 ,47.54]\n",
    "#Following code is used to find out MSE of prediction with Gradient boosting algorithm having estimator 2.\n",
    "MSE_2=(sum((Y-Y_predict)**2))/len(Y)\n",
    "print('MSE for two estimators :',MSE_2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ad5d0ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for three estimators : 380.05602055555556\n"
     ]
    }
   ],
   "source": [
    "# 2) Let us now use GradientBoostingRegressor with 3 estimators to train the model and to predict the age for the same inputs. \n",
    "GB=GradientBoostingRegressor(n_estimators=3)\n",
    "GB.fit(X,Y)\n",
    "Y_predict=GB.predict(X) #ages predicted by model with 3 estimators\n",
    "Y_predict\n",
    "# Output\n",
    "#Y_predict=[36.907, 34.3325, 34.3325, 43.0045, 36.907 , 46.663 , 43.0045, 46.663 , 50.186]\n",
    "#Following code is used to find out MSE of prediction with Gradient boosting algorithm having estimator 3.\n",
    "MSE_3=(sum((Y-Y_predict)**2))/len(Y)\n",
    "print('MSE for three estimators :',MSE_3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7520f1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for fifty estimators : 156.5667260994211\n"
     ]
    }
   ],
   "source": [
    "# 3) Let us now use GradientBoostingRegressor with 50 estimators to train the model and to predict the age for the same inputs.\n",
    "GB=GradientBoostingRegressor(n_estimators=50)\n",
    "GB.fit(X,Y)\n",
    "Y_predict=GB.predict(X) #ages predicted by model with 50 estimators\n",
    "Y_predict\n",
    "# Output\n",
    "#Y_predict=[25.08417833, 15.63313919, 15.63313919, 47.46821839, 25.08417833,       60.89864242, 47.46821839, 60.89864242, 73.83164334]\n",
    "#Following code is used to find out MSE of prediction with Gradient boosting algorithm having estimator 50.\n",
    "MSE_50=(sum((Y-Y_predict)**2))/len(Y)\n",
    "print('MSE for fifty estimators :',MSE_50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b9ec61",
   "metadata": {},
   "source": [
    "Observation:\n",
    "As we can see here, MSE reduces as we increase the estimator value. The situation comes where MSE becomes saturated which means even if we increase the estimator value there will be no significant decrease in MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93a5ba90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding the best estimator with GridSearchCV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "febab0be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best estimator returned by GridSearch CV is: GradientBoostingRegressor(n_estimators=19)\n",
      "MSE for best estimators : 164.2298548605391\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "model=GradientBoostingRegressor()\n",
    "params={'n_estimators':range(1,200)}\n",
    "grid=GridSearchCV(estimator=model,cv=2,param_grid=params,scoring='neg_mean_squared_error')\n",
    "grid.fit(X,Y)\n",
    "print(\"The best estimator returned by GridSearch CV is:\",grid.best_estimator_)\n",
    "#Output\n",
    "#The best estimator returned by GridSearch CV is:  GradientBoostingRegressor(n_estimators=19)\n",
    "GB=grid.best_estimator_\n",
    "GB.fit(X,Y)\n",
    "Y_predict=GB.predict(X)\n",
    "Y_predict\n",
    "#output:\n",
    "#Y_predict=[27.20639114, 18.98970027, 18.98970027, 46.66697477, 27.20639114,58.34332496, 46.66697477, 58.34332496, 69.58721772]\n",
    "MSE_best=(sum((Y-Y_predict)**2))/len(Y)\n",
    "print('MSE for best estimators :',MSE_best)\n",
    "#Following code is used to find out MSE of prediction for Gradient boosting algorithm with best estimator value given by GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970ded4b",
   "metadata": {},
   "source": [
    "Observation:\n",
    "You may think that MSE for n_estimator=50 is better than MSE for n_estimator=19. Still GridSearchCV returns 19 not 50. Actually, we can observe here is until 19 with each increment in estimator value the reduction in MSE was significant, but after 19 there is no significant decrease in MSE with increment in estimators. So, n_estimator=19 was returned by GridSearchSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4efdb3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
