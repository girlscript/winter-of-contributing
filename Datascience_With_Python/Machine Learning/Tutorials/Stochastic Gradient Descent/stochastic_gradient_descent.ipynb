{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Stochastic Gradient",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQYQNoOD3rEy"
      },
      "source": [
        "# Coding Implementation of Stochastic Gradient"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GWrGJARbIezJ"
      },
      "source": [
        "Stochastic gradient descent is a very popular and common algorithm used in various Machine Learning algorithms, most importantly forms the basis of Neural Networks. \n",
        "\n",
        "I recommend proper knowledge of Linear Regression and how it works for proper understanding of this topic.\n",
        "\n",
        "Also before coming to the coding implmentation, go through the theory in the Readme file to understand how the things are actually working internally in this method.\n",
        "\n",
        "We have used the Iris Data Set for our implmentation. This is a famous dataset and is used for Classification as it contains 3 species of Iris:\n",
        "- Setosa\n",
        "- Versicolor\n",
        "- Vriginica\n",
        "\n",
        "Now let's get into the coding and see how things are working."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5QesqDrOuVfa"
      },
      "source": [
        "## Data prepration\n",
        "We load the Iris dataset that is by default available in the Scikit learn module"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rzZmj35HzHK6"
      },
      "source": [
        "from sklearn.datasets import load_iris\n",
        "iris = load_iris()  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IDXcIqH4ujTW"
      },
      "source": [
        "The iris dataset comes in a dictionary data structure. So the features of the dataset are stored in a key \"data\" and the target is inside a key \"target\". So here we list all the keys in the dictionary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p184ySrMsOgy",
        "outputId": "c3e061c8-75fd-471b-c075-e6cf248f3989"
      },
      "source": [
        "list(iris.keys())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['data', 'target', 'target_names', 'DESCR', 'feature_names', 'filename']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMCmnBv-vOLc"
      },
      "source": [
        "We dont need all thenkeys. We only require the features and the respective classes or target. So we store them under attributes in a pandas dataframe. Data or the features are stored in a dataframe **ir** and we make a new **Species** column to store the target."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "lA7ckmVNsY50",
        "outputId": "303dd55c-30f6-40b3-a6de-60d9b24dde67"
      },
      "source": [
        "import pandas as pd\n",
        "ir = pd.DataFrame(iris['data'])\n",
        "ir['Species'] = pd.DataFrame(iris['target'])\n",
        "ir #printing the entire dataframe"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>Species</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145</th>\n",
              "      <td>6.7</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.2</td>\n",
              "      <td>2.3</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>6.3</td>\n",
              "      <td>2.5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.9</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>6.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>6.2</td>\n",
              "      <td>3.4</td>\n",
              "      <td>5.4</td>\n",
              "      <td>2.3</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>5.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.1</td>\n",
              "      <td>1.8</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>150 rows Ã— 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       0    1    2    3  Species\n",
              "0    5.1  3.5  1.4  0.2        0\n",
              "1    4.9  3.0  1.4  0.2        0\n",
              "2    4.7  3.2  1.3  0.2        0\n",
              "3    4.6  3.1  1.5  0.2        0\n",
              "4    5.0  3.6  1.4  0.2        0\n",
              "..   ...  ...  ...  ...      ...\n",
              "145  6.7  3.0  5.2  2.3        2\n",
              "146  6.3  2.5  5.0  1.9        2\n",
              "147  6.5  3.0  5.2  2.0        2\n",
              "148  6.2  3.4  5.4  2.3        2\n",
              "149  5.9  3.0  5.1  1.8        2\n",
              "\n",
              "[150 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQgexeIOv9uP"
      },
      "source": [
        "In the species column, there are numbers only. But those numbers represent the species of the iris flower. Like we have 3 species of Iris, Setosa, versicolor and Virginica. So we are assigning each number the specie name."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkXPuaansaXH"
      },
      "source": [
        "ir['Species'] = ir['Species'].replace({0: \"setosa\", 1: \"versicolor\", 2: 'virginica'})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "diEFMkJ6wJa4"
      },
      "source": [
        "We can use Stochastic Gradient in 3 classes as well. But to make it simpler to understand I am converting this dataframe in a binary dataframe. Basically I am assigning the species with Setosa with 1 and the rest all Species with 0. So my model with predict that whther the given features are of Setosa or not."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y5UySbqPsfli",
        "outputId": "21dfdeab-f133-45e5-da9e-d7eb4c926aa4"
      },
      "source": [
        "for i in range(len(ir['Species'])):\n",
        "    if ir['Species'][i] == 'setosa':\n",
        "        ir['Species'][i] = 1\n",
        "    else:\n",
        "        ir['Species'][i] = 0\n",
        "ir['Species']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      1\n",
              "1      1\n",
              "2      1\n",
              "3      1\n",
              "4      1\n",
              "      ..\n",
              "145    0\n",
              "146    0\n",
              "147    0\n",
              "148    0\n",
              "149    0\n",
              "Name: Species, Length: 150, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5MCR-JJzx4rz"
      },
      "source": [
        "First, we will separate the dataset as training set and test set using the train_test_split function in sklearn library. Before that, the features and the target needs to be separated.\n",
        "\n",
        "The features that is x1,x2 and so on are stored in ir_features and the target variable stored in ir_label"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NAlfYLxPsm5-"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "ir_features = ir.drop(columns = 'Species')\n",
        "ir_label = ir['Species']\n",
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    ir_features, ir_label, \n",
        "    test_size = 0.2,\n",
        "    random_state = 10\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76jJEz-lyvNy"
      },
      "source": [
        "Now, we have training and test set separately. As I explained before, we will randomly select a few data points for each iteration in SGD method. I will combine the x_train and y_train because we will need the y_train as well for training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o0T4UHb8stUo",
        "outputId": "58a015f3-dde7-4116-8902-44c6b76ebc05"
      },
      "source": [
        "x_train['Species'] = y_train\n",
        "df = x_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bn_P-4KY0Eec"
      },
      "source": [
        "Below is the function to randomly select 12 data points from the training set for each iteration. In the original iris dataset, there were 50 â€˜setosaâ€™ and 100 other species. That means there are 50 positive class and 100 negative class data. The sample should be accorning to that ratio. So, letâ€™s take 4 data from the positive class and 8 data from the negative class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EdR1qYcfsx7S"
      },
      "source": [
        "def stratified_spl(df):\n",
        "    df1 = df[df['Species'] == 1]\n",
        "    df0 = df[df['Species'] == 0]\n",
        "    df1_spl = df1.sample(n=4)\n",
        "    df0_spl = df0.sample(n=8)\n",
        "    return pd.concat([df1_spl, df0_spl])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vS3CdqDS0Ja8"
      },
      "source": [
        "here we have used the Signmoid Activation function.\n",
        "Sigmoid activation function is a binary classifier and it classifies a given input in two catergories,either 0 or 1.\n",
        "\n",
        "The mathematical Equation is given as below\n",
        "\n",
        "![picture](https://drive.google.com/uc?id=1i5N_Fz9JNKTKzzIP7-CPGY5RnFeLuLs4)\n",
        "\n",
        "The Graph of this function is as follows\n",
        "\n",
        "![picture](https://drive.google.com/uc?id=1ZPvwsG7QohyAHZCy46v2IN2e6Y58jDnO)\n",
        "\n",
        "As you can clearly see that it sets the values to either 0 or 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCK1JDhVtHQF"
      },
      "source": [
        "def hypothesis(X, w):\n",
        "    z = np.dot(w, X.T)\n",
        "    return 1/(1+np.exp(-(z)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m_Rxtcai1lT8"
      },
      "source": [
        "The next function will separate the features and target of the mini training set of 12 data again for the training purpose.\n",
        "As you can see in the linear formula above, we need a bias W0. An extra feature of 1s is added as a bias term. We will improve the bias term as well in each iteration."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMi1-V-EtKTY"
      },
      "source": [
        "def xy(df):\n",
        "    df_features = df.drop(columns = 'Species')\n",
        "    df_label = df['Species']\n",
        "    df_features['00'] = [1]*12\n",
        "    return df_features, df_label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oXdKheDY1rp2"
      },
      "source": [
        "This function will calculate the predicted target first and then the Mean Square Error(MSE)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BdcxPNcKtNXV"
      },
      "source": [
        "def error(X, y, w):\n",
        "    n = len(X)\n",
        "    yp = hypothesis(X, w)\n",
        "    return np.sum((yp-y)**2)/n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38tZMUnX1xmt"
      },
      "source": [
        "All the functions are ready. Now gradient descent function. In each iteration,\n",
        "1. It will sample 12 data points using the stratified_spl function defined before.\n",
        "2. Then split the features and target as X and y.\n",
        "3. Calculate the predicted y using Ws and Xs.\n",
        "4. Update the Ws using the gradient descent formula."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7psVrkb-2Crk"
      },
      "source": [
        "Here we collect the errors in each iteration and the Ws."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSlFBKtotPsr"
      },
      "source": [
        "def grad_des(df, w, alpha, epoch):\n",
        "    j = []\n",
        "    w1 = []\n",
        "    w1.append(w)\n",
        "    for i in range(epoch):\n",
        "        d = stratified_spl(df)\n",
        "        X, y = xy(d)\n",
        "        n= len(X)\n",
        "        yp = hypothesis(X, w)\n",
        "        \n",
        "        for i in range(4):\n",
        "            w[i] -= (alpha/n) * np.sum(-2*X[i]*(y-yp))\n",
        "        w[4] -= (alpha/n) *np.sum(-2*(y-yp))\n",
        "        w1.append(list(w))\n",
        "        j.append(error(X, y, w))\n",
        "    return j, w1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rYlpmVSN2HNH"
      },
      "source": [
        "We are randomly initializing Ws. There are total of five features including the bias. So, for each feature or X, we need to initialize a W as we saw in the linear formula in the beginning."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H_HxayT8tUIo",
        "outputId": "72ad1776-da1b-4383-cf03-48c8a5ce8cbb"
      },
      "source": [
        "import numpy as np\n",
        "w = np.random.rand(5)\n",
        "w"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.60308338, 0.55779124, 0.19924558, 0.13887832, 0.76156233])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pPoFM3fN2RJM"
      },
      "source": [
        "Now, use the gradient descent function using the step size (alpha) as 0.01 for 100 iterations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJVH4ey1tZEl"
      },
      "source": [
        "j, w1 = grad_des(x_train, w, 0.01, 100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-2nvFwX2ZPW"
      },
      "source": [
        "This should give us 100 w1 for 100 iterations. Using this 100 w1s, we can calculate 100 MSEs to observe the change in MSE in each iteration. I need a function that should calculate the predicted y for each w1 and then error."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kNvEMIvgtcFF"
      },
      "source": [
        "def err_test(X, y, w):\n",
        "    er = []\n",
        "    for i in range(len(w1)):\n",
        "        er.append(error(X, y, w[i]))\n",
        "    return er"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TlkSwgPw2eLG"
      },
      "source": [
        "This is the plot function and we are visualising the MSE in each iteration."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AuWF0cBYtdWD"
      },
      "source": [
        "def plot(X, y, w):\n",
        "    error = err_test(X, y, w)\n",
        "    return plt.scatter(range(len(error)), error)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R3J373sc2mAk"
      },
      "source": [
        "in the above we have added the target column in x_train. So we drop or remove that column and add the bias."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16S7BjECthof"
      },
      "source": [
        "X = x_train.drop(columns = 'Species')\n",
        "X['00'] = [1]*len(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "caY_V5fE2xmg"
      },
      "source": [
        "This part plots the MSE for training set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "XD7BS3nJtlFG",
        "outputId": "b0b4e40e-d987-4e69-a2ce-cffea08965d2"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plot(X, y_train, w1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7f0dffbde490>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GIhfNgVc23Um"
      },
      "source": [
        "This is the accuracy function to check the accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tOtugOk7t97-"
      },
      "source": [
        "def accuracy(X, y, w):\n",
        "    yp = hypothesis(X, w)\n",
        "    for i in range(len(yp)):\n",
        "        if yp[i] >=0.5:\n",
        "            yp[i] = 1\n",
        "        else:\n",
        "            yp[i] = 0\n",
        "    return sum(yp == y)/len(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Q4vQer33DQ8"
      },
      "source": [
        "Now to understand how accuracy changews with each iteration we have define this function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-8v2jzquDUg"
      },
      "source": [
        "def accuracy_series(X, y, w1):\n",
        "    acc = []\n",
        "    for i in range(len(w1)):\n",
        "        acc.append(accuracy(X, y, w1[i]))  \n",
        "    return acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-O4ItjFI3Ke0"
      },
      "source": [
        "We are using this function to see the accuracy series for the training set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cr3GpfHhuFPs",
        "outputId": "f3d36f33-2542-4a7a-cc77-b100628e72f2"
      },
      "source": [
        "np.array(accuracy_series(X, y_train, w1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.        , 0.33333333, 0.33333333, 0.33333333, 0.33333333,\n",
              "       0.33333333, 0.33333333, 0.33333333, 0.425     , 0.91666667,\n",
              "       0.99166667, 1.        , 1.        , 1.        , 1.        ,\n",
              "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "       1.        ])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxN3xMOn3QVb"
      },
      "source": [
        "You can see that with each iteration the accuracy has changed. Initially it was 33% then it increased to 42.5% and then to 91.6% and to 99.1%. Finally the accuracy became 100% or 1 which means our model has zero error and is 100% accurate."
      ]
    }
  ]
}