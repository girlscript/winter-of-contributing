## Topic: Data Science with Python : Hierarchical Clustering #1830
## Video link: [Hierarchical Clustering](https://drive.google.com/file/d/1cDb6YnzPaS8oeIXqKT_RM_jpvM2PHUG6/view?usp=sharing)

**Clustering** is a data mining technique which is used to group the data based on their similarities or differences.

*Clustering types:*
- Hierarchical clustering
- Non- Hierarchical clustering

**Hierarchical clustering**

- Hierarchical clustering follows a hierarchy. 
- It can be categorized into two types:*agglomerative clustering and divisive clustering*

**Agglomerative Clustering**
- Bottom-up approach.
- First data points are grouped separately and merged into a single cluster iteratively based on similarity.
- Distance used to measure the similarity between data points.

**Divisive Clustering**
- Top-down approach.
- First data points are grouped into a single cluster and separated into several clusters iteratively based on similarity.
- Distance used to measure the similarity between data points.


![Capture](https://user-images.githubusercontent.com/79050917/134517426-5a6b041b-9989-4593-b5dd-4b612d37b60c.PNG)

**What makes clusters good:**

Intra-class similarity is high and inter â€“class similarity is low


**Challenges:**

- In accurate results as it involves human intervention to validate the output.
- Computational complexity due to large training data.

**Advantages:**

- No apriori information about the number of clusters required.

- Easy to implement and gives best result in some cases.

**Disadvantages:**

- Algorithm can never undo what was done previously.
## **Conclusion:**

Hierarchical clustering is a powerful technique that allows you to build tree structures from data similarities. You can now see how different sub-clusters relate to each other, and how far apart data points are. 
