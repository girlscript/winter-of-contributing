{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TupYSlevM_Ut"
   },
   "source": [
    "# **Depth Map from Stereo Pair Images**\n",
    "\n",
    "Open CV is a huge open-source library for the computer vision,machine learning , and image processing and now it plays a major role in real-time operation which is very important in today's systems. In 3D computer graphics and computer vision, a depth map is an image or image channel that contains information relating to the distance of the surfaces of scene objects from a viewpoint. The term is related to and may be analogous to depth buffer, Z-buffer, Z-buffering and Z-depth. Let us first understand the concept of stereo images and the depth of an image.\n",
    "\n",
    "While walking or running, we notice that objects close to us seem to move faster than those far away. We call this underlying effect ‘parallax’. We can use this phenomenon to extract geometrical information from any spectacle. From numerous images of the same arena from various points of view, we can estimate a number of things; one of them being the interspace of the components. This distance is known as the depth of the image and the images are known as stereo images. Now, by pursuing the span of points amongst these depictions, we find the stretch of these spots from the camera.\n",
    "\n",
    "## **What is Depth Map?**\n",
    "A depth map is a picture where every pixel has depth information (rather than RGB) and it normally represented as a greyscale picture. Depth information means the distance of surface of scene objects from a viewpoint. \n",
    "\n",
    "## **Stereo Images**\n",
    "Two images with slight offset. For example, take a picture of an object from the center. Move your camera to your right by 6 cms while keeping the object at the centre of the image.Look for the same thing in both pictures and infer depth from the difference in position. This is called stereo matching. To have best results.Avoid distortions.\n",
    "\n",
    "![Stereo image](https://th.bing.com/th/id/OIP.H9n17OT2NO9o2KP5XmxyegHaDX?pid=ImgDet&rs=1)\n",
    "\n",
    "## **Approach**\n",
    "* Collect or take stereo images.\n",
    "* Import OpenCV and matplotlib libraries.\n",
    "* Read both left and right images.\n",
    "* Calculate disparity using stereo.compute.\n",
    "\n",
    "## **Formula behind Intuition**\n",
    "\n",
    "![Stereo depth](https://docs.opencv.org/3.4/stereo_depth.jpg)\n",
    "\n",
    "The above diagram contains equivalent triangles. Writing their equivalent equations will yield us following result:\n",
    "\n",
    "``` disparity=x−x′=Bf/Z```\n",
    "\n",
    "x  and x′ are the distance between points in image plane corresponding to the scene point 3D and their camera center. B is the distance between two cameras (which we know) and f is the focal length of camera (already known). So in short, the above equation says that the depth of a point in a scene is inversely proportional to the difference in distance of corresponding image points and their camera centers. So with this information, we can derive the depth of all pixels in an image.\n",
    "\n",
    "So it finds corresponding matches between two images. We have already seen how epiline constraint make this operation faster and accurate. Once it finds matches, it finds the disparity. Let's see how we can do it with OpenCV.\n",
    "\n",
    "## **Implementation using Steps**\n",
    "\n",
    "### **Test Case 1:**\n",
    "\n",
    "Steps to follow:\n",
    "\n",
    "1. Here, we first import the libraries.\n",
    "2. Then the images are read using imread() for both left and right.\n",
    "3. Now create StereoBM object mentioning the properties numDisparities and blockSize.\n",
    "4. Then we compute the disparity on stereo variable using compute().\n",
    "5. Display the image and disparity inbetween them using grayscale and its plot.\n",
    "\n",
    "Images to be used:\n",
    "\n",
    "Left image will look like this.\n",
    "\n",
    "![image1](https://media.geeksforgeeks.org/wp-content/uploads/20200623130832/lef2t.jpg)\n",
    "\n",
    "Similarly, you can get the right image of the same object from the images folder.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GLctBpsofOXM"
   },
   "source": [
    "```python\n",
    "# import OpenCV and pyplot\n",
    "import cv2 as cv\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# read left and right images\n",
    "imgR = cv.imread('right.png', 0)\n",
    "imgL = cv.imread('left.png', 0)\n",
    "\n",
    "# creates StereoBm object\n",
    "stereo = cv.StereoBM_create(numDisparities = 16,blockSize = 15)\n",
    "\n",
    "# computes disparity\n",
    "disparity = stereo.compute(imgL, imgR)\n",
    "\n",
    "# displays image as grayscale and plotted\n",
    "plt.imshow(disparity, 'gray')\n",
    "plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Output:**\n",
    "\n",
    "![output](https://media.geeksforgeeks.org/wp-content/uploads/20200623130146/Output280.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Test Case 2:**\n",
    "\n",
    "Similarly for second test case we take different image and all other steps are same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from matplotlib import pyplot as plt\n",
    "imgL = cv.imread('tsukuba_l.png',0)\n",
    "imgR = cv.imread('tsukuba_r.png',0)\n",
    "stereo = cv.StereoBM_create(numDisparities=16, blockSize=15)\n",
    "disparity = stereo.compute(imgL,imgR)\n",
    "plt.imshow(disparity,'gray')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "Below image contains the original image (left) and its disparity map (right). As you can see, the result is contaminated with high degree of noise. By adjusting the values of numDisparities and blockSize, you can get a better result.\n",
    "\n",
    "![test case 2](https://docs.opencv.org/3.4/disparity_map.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zm_ImNfHfPBp"
   },
   "source": [
    "## **Fine Tuning the Parameters of StereoBM**\n",
    "\n",
    "There are some parameters when you get familiar with StereoBM, and you may need to fine tune the parameters to get better and smooth results. \n",
    "\n",
    "Parameters:\n",
    "\n",
    "* **texture_threshold:** filters out areas that don't have enough texture for reliable matching\n",
    "\n",
    "* **Speckle range and size:** Block-based matchers often produce \"speckles\" near the boundaries of objects, where the matching window catches the foreground on one side and the background on the other. In this scene it appears that the matcher is also finding small spurious matches in the projected texture on the table. To get rid of these artifacts we post-process the disparity image with a speckle filter controlled by the speckle_size and speckle_range parameters. speckle_size is the number of pixels below which a disparity blob is dismissed as \"speckle.\" speckle_range controls how close in value disparities must be to be considered part of the same blob.\n",
    "\n",
    "* **Number of disparities:** How many pixels to slide the window over. The larger it is, the larger the range of visible depths, but more computation is required.\n",
    "\n",
    "* **min_disparity:** the offset from the x-position of the left pixel at which to begin searching.\n",
    "\n",
    "* **uniqueness_ratio:** Another post-filtering step. If the best matching disparity is not sufficiently better than every other disparity in the search range, the pixel is filtered out. You can try tweaking this if texture_threshold and the speckle filtering are still letting through spurious matches.\n",
    "\n",
    "* **prefilter_size and prefilter_cap:** The pre-filtering phase, which normalizes image brightness and enhances texture in preparation for block matching. Normally you should not need to adjust these.\n",
    "\n",
    "## **Uses of Depth Map**\n",
    "\n",
    "1. **Simulating shallow depths of field** - where some parts of a scene appear to be out of focus. Depth maps can be used to selectively blur an image to varying degrees. A shallow depth of field can be a characteristic of macro photography and so the technique may form a part of the process of miniature faking.\n",
    "\n",
    "2. **Shadow mapping** - part of one process used to create shadows cast by illumination in 3D computer graphics. In this use, the depth maps are calculated from the perspective of the lights, not the viewer.\n",
    "\n",
    "3. In computer vision single-view or multi-view images depth maps, or other types of images, are used to model 3D shapes or reconstruct them. Depth maps can be generated by 3D scanners or reconstructed from multiple images.\n",
    "\n",
    "4. In Machine vision and computer vision, to allow 3D images to be processed by 2D image tools.\n",
    "\n",
    "## **Limitations of Depth Maps**\n",
    "\n",
    "* Single channel depth maps cannot convey multiple distances where they occur within the view of a single pixel. This may occur where more than one object occupies the location of that pixel. This could be the case - for example - with models featuring hair, fur or grass. More generally, edges of objects may be ambiguously described where they partially cover a pixel.\n",
    "\n",
    "* Depending on how they are generated, depth maps may represent the perpendicular distance between an object and the plane of the scene camera. For example, a scene camera pointing directly at - and perpendicular to - a flat surface may record a uniform distance for the whole surface. In this case, geometrically, the actual distances from the camera to the areas of the plane surface seen in the corners of the image are greater than the distances to the central area. For many applications, however, this discrepancy is not a significant issue.\n",
    "\n",
    "* Depending on the intended use of a depth map, it may be useful or necessary to encode the map at higher bit depths. For example, an 8 bit depth map can only represent a range of up to 256 different distances.\n",
    "\n",
    "## **Summary**\n",
    "\n",
    "Thus, Depth maps are an important aspect for the stereo pair images for 3D reconstruction and using this simple implementation gives us an insight in the disparity which is faced in different dimensions are placed. OpenCV provides us this module so that we can work upon finding the disparty ratio and correctly implement it in our models. The mathematical approach of the concept of stereo images is also clearly discussed to give a large perspective on this topic and correlation between depth maps and stereo pair images.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Depth Map from Stereo Pair Images.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
