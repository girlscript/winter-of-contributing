# Outline

### 1. Introduction to transformers.
Transformers introduced back in 2017 took the NLP world by storm. They were known for their long range memory dependencies. Largely used in machine translation and speech recognition tasks.
### 2. Attention Mechanisms.
Transformers gets it's powers from the attention module. In the video, we'll clearly discuss how attention works and responsible for creating association between individual elements in an input.
### 3. Transformers in vision.
Researchers later extended the research on Transformers towards computer vision. We'll briefly discuss how the slight modifications to the architecture takes in images to learn from. 
### 4. Vision Transformer(ViT)
This paper released in december 2020 introduced a transformer architecture which consists of transformer encoder. For the input, it takes in patches of the image and passes it through projection layer, adding embedding and position encodings. In the video, we'll clearly discuss the architecture.  
### 5. Code explanation.
An overview explaining the code for ViT. (Do check the notebook file in the current folder)

## Link to the video â¬‡

[![image](https://user-images.githubusercontent.com/30192967/137440669-f45c61d5-a3e5-4413-a5e0-fc901344624e.png)](https://youtu.be/3QTltiwcncc)

