# Statistics, Probability and Inference

## Video link: [Statistics, Probability and Inference](https://drive.google.com/file/d/1L7N_CgGvNoLCN9c5UqzZUTFNGKbbjhkP/view?usp=sharing)

## Importance of Statistics for Data Science

Most Data Scientists always invest more in pre-processing of data. This requires a good understanding of statistics. There are few general steps that always need to be performed to process any data.

- Identify the importance of features by using various statistical tests.
- Finding the relationship between features to eliminate the possibility of duplicate features.
- Converting the features into the required format.
- Normalizing and scaling the data. This step also involves the identification of the distribution of data and the nature of data.
- Taking the data for further processing by using required adjustments in the data.
- After processing the data identify the right mathematical approach/model.
- Once the results are obtained the results are verified on the different accuracy measurement scales.

## **Probability:**
- Classification models must predict a probability of class membership.
- Algorithms are designed using probability (e.g. Naive Bayes).
- Learning algorithms will make decisions using probability (e.g. information gain).
- Sub-fields of study are built on probability (e.g. Bayesian networks).
- Algorithms are trained under probability frameworks (e.g. maximum likelihood).
- Models are fit using probabilistic loss functions (e.g. log loss and cross-entropy).
- Model hyperparameters are configured with probability (e.g. Bayesian optimization).
- Probabilistic measures are used to evaluate model skill (e.g. brier score, ROC).

![image](https://user-images.githubusercontent.com/79050917/143614812-d7ed43bc-8f02-42b5-ac32-8570776ee138.png)

## **Inference**
- Machine learning (ML) inference is the process of running live data points into a machine learning algorithm (or “ML model”) to calculate an output such as a single numerical score. 
- This process is also referred to as “operationalizing an ML model” or “putting an ML model into production.” When an ML model is running in production, it is often then described as artificial intelligence (AI) since it is performing functions similar to human thinking and analysis.

![image](https://user-images.githubusercontent.com/79050917/143614764-de5eb1ad-74cd-4050-9db1-7b2d4e7f99e3.png)

## **Benefits:**
- For easy predictions
- Reduces the complexity
- Makes the dataset ease than before

## **Conclusion:**
- Statistics have the advantage of finding out meaningful insights. Probability is used in many models and making the best predictions. The inference is the process of running live data points into a machine-learning algorithm to calculate an output such as a single numerical score. All three helps and reduce the work and complexity of the dataset.

