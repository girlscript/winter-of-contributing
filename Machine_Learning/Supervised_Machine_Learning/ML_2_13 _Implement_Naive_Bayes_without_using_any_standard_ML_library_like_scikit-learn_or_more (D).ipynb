{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Naive Bayes Classifier from scratch using Titanic dataset**\n",
    "Understanding the concepts behind each statistical model is an important element of studying ML. However, Scikit-learn appears to the user as a mystical black box. The Naive Bayes method is easy to learn and fun to use. It will be presented in Python and applied to the Titanic Survival prediction problem.\n",
    "\n",
    "![Naive Bayes Classifier](Assets/NBC.jfif)\n",
    "\n",
    "## What is Bayes Theorem?\n",
    "\n",
    "The Bayes theorem is a mathematical formula to calculate conditional probability, named after 18th-century British mathematician Thomas Bayes. The possibility of an outcome occurring based on the likelihood of a preceding outcome occurring is known as conditional probability. Given fresh or more facts, Bayes' theorem can be used to alter previous forecasts or theories (update probability). Bayes' theorem is used in finance to assess the risk of lending money to prospective investors.\n",
    "\n",
    "\n",
    "The Bayes theorem, commonly known as Bayes' Rule or Bayes' Law, is the cornerstone of Bayesian statistics.\n",
    "\n",
    "It expresses the likelihood of an event based on past knowledge of circumstances that may be relevant to the event. Given that ( x ) has occurred, we may calculate the likelihood of ( y ) occurring using Bayes theory. The evidence ( x ) is the evidence, the previous experience ( y ) is the prior knowledge, and the likelihood ( P(x|y)) is the likelihood. The predictor variables are assumed to be independent in this case.\n",
    "\n",
    "It's equation is as follows:\n",
    "\n",
    "\\\\( P(y|x)= \\dfrac{P(x|y)P(y)}{P(x)} \\\\)\n",
    "where, \n",
    "* \\\\( y,x \\\\) = Events\n",
    "* \\\\( P(y|x) \\\\) = Probability of \\\\( y \\\\) given \\\\( x \\\\)\n",
    "* \\\\( P(x|y) \\\\) = Probability of \\\\( x \\\\) given \\\\( y \\\\)\n",
    "* \\\\( P(y), P(x) \\\\) = Independent probabilities of \\\\( y \\\\) and \\\\( x \\\\)\n",
    "\n",
    "The Naive Bayes Methods are a series of supervised learning algorithms based on Bayes' theorem and the \"naive\" assumption of conditional independence between every pair of features given the class variable's value.\n",
    "\n",
    "The variable ( y ) in our example is the class variable (Survival 0 or 1), which indicates whether a passenger would survive or not under the circumstances. The parameters/features are represented by the variable ( X ). ( X ) is written as ( X=(x 1, x 2,..., x n) ) and can be mapped to Age, Class, Sex, and so on. We get by inserting for ( X) in the Bayes Rule and expanding with the chain rule.\n",
    "        \n",
    "\\\\( P(y|x_{1}, x_{2}, ..., x_{n})= \\dfrac{P(x_{1}|y)P(x_{2}|y)...P(x_{n}|y)P(y)}{P(x_{1})P(x_{2})...P(x_{n})} \\\\)\n",
    "\n",
    "By examining the dataset, you can now compute the values for each likelihood and plug them into the equation. The class variable ( y ) has two possible outcomes in our case: 0 or 1. So, for each passenger, the survival chances for each situation of '*Survival*' or '*No survival*' (1 or 0, respectively) must be determined. The final outcome is the one with the highest likelihood. That is, the guy will survive if ( P(1) > P(0) ).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "df_train=pd.read_csv('train.csv')\n",
    "df_test=pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets do some basic feature engineering, for simplicity we will be using 3 features only: Class, Sex and Age):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender={\"male\":0, \"female\":1}\n",
    "df_train.Sex=[gender[item] for item in df_train.Sex]\n",
    "df_test.Sex=[gender[item] for item in df_test.Sex]\n",
    "\n",
    "df_train.Age.fillna(df_train.Age.mean(), inplace=True)\n",
    "df_test.Age.fillna(df_test.Age.mean(), inplace=True)\n",
    "\n",
    "df_train.Age=df_train.Age.astype(int)\n",
    "df_test.Age=df_test.Age.astype(int)\n",
    "\n",
    "#Ages grouped\n",
    "data = [df_train, df_test]\n",
    "for dataset in data:\n",
    "    dataset.loc[ dataset['Age'] <= 11, 'Age'] = 0\n",
    "    dataset.loc[(dataset['Age'] > 11) & (dataset['Age'] <= 18), 'Age'] = 1\n",
    "    dataset.loc[(dataset['Age'] > 18) & (dataset['Age'] <= 22), 'Age'] = 2\n",
    "    dataset.loc[(dataset['Age'] > 22) & (dataset['Age'] <= 27), 'Age'] = 3\n",
    "    dataset.loc[(dataset['Age'] > 27) & (dataset['Age'] <= 33), 'Age'] = 4\n",
    "    dataset.loc[(dataset['Age'] > 33) & (dataset['Age'] <= 40), 'Age'] = 5\n",
    "    dataset.loc[(dataset['Age'] > 40) & (dataset['Age'] <= 66), 'Age'] = 6\n",
    "    dataset.loc[ dataset['Age'] > 66, 'Age'] = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Machine Learning model construction starts here\n",
    "\n",
    "For 3 features, so the Bayes rule will look like the following equation,\n",
    "\n",
    "\\\\( P(y|x_{1}, x_{2},x_{3})= \\dfrac{P(x_{1}|y)P(x_{2}|y)P(x_{3}|y)P(y)}{P(x_{1})P(x_{2})P(x_{3})} \\\\)\n",
    "\n",
    "where \n",
    "\n",
    "\\\\( P(y) \\\\) = Probability of survival (for 0 and for 1), so it is a 2-dimensional array.\n",
    "* \\\\( P(x_{1}) \\\\) = Probability of Pclass, it is a 3-dimensional array (denoted as p_Class in the code)\n",
    "* \\\\( P(x_{2}) \\\\) = Probability of gender, 2-dimensional array (denoted as p_Sex in the code)\n",
    "* \\\\( P(x_{3}) \\\\) = Probability of Age, 8-dimensional array (denoted as p_Age in the code)\n",
    "\n",
    "and the conditional probabilities\n",
    "\n",
    "*  \\\\( P(x_{1}|y) \\\\) = Probability of Pclass given survival (0 or 1)\n",
    "*  \\\\( P(x_{2}|y) \\\\) = Probability of gender given survival (0 or 1)\n",
    "*  \\\\( P(x_{3}|y) \\\\) =  Probability of Age given survival (0 or 1)\n",
    "\n",
    "The probabilities are calculated below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#probabilities of the features\n",
    "    \n",
    "Class_counts=df_train['Pclass'].value_counts()  \n",
    "p_Class=Class_counts/len(df_train)\n",
    "\n",
    "Sex_counts=df_train['Sex'].value_counts()\n",
    "p_Sex=Sex_counts/len(df_train)\n",
    "\n",
    "Age_counts=df_train['Age'].value_counts()\n",
    "p_Age=Age_counts/len(df_train)\n",
    "\n",
    "# Survival and Death probabilities\n",
    "y_counts=df_train['Survived'].value_counts()\n",
    "p_y=y_counts/len(df_train)\n",
    "\n",
    "df_survived=df_train.loc[df_train['Survived'] == 1]\n",
    "df_died=df_train.loc[df_train['Survived'] == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conditional Probabilities are calculated below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P Class Survived : \n",
      " 1    0.397661\n",
      "3    0.347953\n",
      "2    0.254386\n",
      "Name: Pclass, dtype: float64\n",
      "\n",
      "P Class Died : \n",
      " 3    0.677596\n",
      "2    0.176685\n",
      "1    0.145719\n",
      "Name: Pclass, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Conditional probabilities\n",
    "#class/survived\n",
    "class_survived_counts=df_survived['Pclass'].value_counts()  \n",
    "p_class_survived=class_survived_counts/len(df_survived)\n",
    "\n",
    "# class/died\n",
    "class_died_counts=df_died['Pclass'].value_counts()  \n",
    "p_class_died=class_died_counts/len(df_died)\n",
    "\n",
    "print(\"P Class Survived : \\n\", p_class_survived)\n",
    "print(\"\\nP Class Died : \\n\", p_class_died)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P Age Survived : \n",
      " 4    0.295322\n",
      "6    0.157895\n",
      "5    0.131579\n",
      "3    0.125731\n",
      "0    0.114035\n",
      "1    0.090643\n",
      "2    0.081871\n",
      "7    0.002924\n",
      "Name: Age, dtype: float64\n",
      "\n",
      "P Age Died : \n",
      " 4    0.367942\n",
      "6    0.158470\n",
      "2    0.116576\n",
      "3    0.114754\n",
      "5    0.105647\n",
      "1    0.072860\n",
      "0    0.052823\n",
      "7    0.010929\n",
      "Name: Age, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Age/survived\n",
    "age_survived_counts=df_survived['Age'].value_counts()  \n",
    "p_age_survived=age_survived_counts/len(df_survived)\n",
    "\n",
    "age_died_counts=df_died['Age'].value_counts()  \n",
    "p_age_died=age_died_counts/len(df_died)\n",
    "\n",
    "print(\"P Age Survived : \\n\", p_age_survived)\n",
    "print(\"\\nP Age Died : \\n\", p_age_died)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P Gender Survived : \n",
      " 1    0.681287\n",
      "0    0.318713\n",
      "Name: Sex, dtype: float64\n",
      "\n",
      "P Gender Died : \n",
      " 0    0.852459\n",
      "1    0.147541\n",
      "Name: Sex, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#sex/survived\n",
    "sex_survived_counts=df_survived['Sex'].value_counts()  \n",
    "p_sex_survived=sex_survived_counts/len(df_survived)\n",
    "\n",
    "sex_died_counts=df_died['Sex'].value_counts()  \n",
    "p_sex_died=sex_died_counts/len(df_died)\n",
    "\n",
    "print(\"P Gender Survived : \\n\", p_sex_survived)\n",
    "print(\"\\nP Gender Died : \\n\", p_sex_died)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, lets define the Bayes Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Bayes(py, px1y, px2y, px3y, px1, px2, px3):\n",
    "    numerator=px1y*px2y*px3y*py\n",
    "    denominator=px1*px2*px3\n",
    "    p=numerator/denominator\n",
    "    return p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The probabilities of survival for each passenger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The chance of Number of passenger will survive is predicted below: \n",
      "      PassengerId  Survived\n",
      "0            892         0\n",
      "1            893         1\n",
      "2            894         0\n",
      "3            895         0\n",
      "4            896         1\n",
      "..           ...       ...\n",
      "413         1305         0\n",
      "414         1306         1\n",
      "415         1307         0\n",
      "416         1308         0\n",
      "417         1309         0\n",
      "\n",
      "[418 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "result_array=[]\n",
    "\n",
    "for i in range(0,418):\n",
    "    feature_class=df_test.iloc[i]['Pclass']\n",
    "    feature_sex=df_test.iloc[i]['Sex']\n",
    "    feature_age=df_test.iloc[i]['Age']\n",
    "    \n",
    "    P_Y1=Bayes(p_y[1], p_class_survived[feature_class], p_sex_survived[feature_sex], p_age_survived[feature_age], p_Class[feature_class], p_Sex[feature_sex], p_Age[feature_age])\n",
    "    P_Y0=Bayes(p_y[0], p_class_died[feature_class], p_sex_died[feature_sex], p_age_died[feature_age], p_Class[feature_class], p_Sex[feature_sex], p_Age[feature_age])\n",
    "    \n",
    "    if P_Y0 > P_Y1:\n",
    "        result=0\n",
    "    else:\n",
    "        result=1\n",
    "        \n",
    "    result_array.append(result)\n",
    "\n",
    "\n",
    "output = pd.DataFrame({'PassengerId': df_test.PassengerId,'Survived': result_array})\n",
    "\n",
    "print(\"The chance of Number of passenger will survive is predicted below: \\n\" ,output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advantages\n",
    "- It is not only a straightforward strategy, but also a quick and accurate one.\n",
    "- The calculation cost of Naive Bayes is quite low.\n",
    "- It can handle a large dataset with ease.\n",
    "- When compared to a continuous variable, it performs well with discrete response variables.\n",
    "- It can be used to solve problems involving numerous classes.\n",
    "- It also performs well when dealing with text analytics issues.\n",
    "- A Naive Bayes classifier outperforms other models like logistic regression when the assumption of independence is met."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Disadvantages\n",
    "- The presumption of distinct characteristics. In practise, getting a group of predictors that are completely independent is nearly impossible.\n",
    "\n",
    "- When there is no training tuple for a specific class, the posterior probability is zero. The model is unable to provide predictions in this scenario. The Zero Likelihood Problem is the name for this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Congratulations, we have successfully learnt using Naive Bayes without using any fancy libraries!\n",
    "\n",
    "Here, we learned about Naïve Bayes algorithm, it's working, Naive Bayes assumption, issues, implementation, advantages, and disadvantages. Along the road, you have also learned model building and evaluation without using scikit-learn for binary and multinomial classes.\n",
    "\n",
    "Naive Bayes is the most straightforward and most potent algorithm. In spite of the significant advances of Machine Learning in the last couple of years, it has proved its worth. It has been successfully deployed in many applications from text analytics to recommendation engines."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
