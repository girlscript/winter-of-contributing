{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# **Naive Bayes Classifier from scratch using Iris Dataset**\r\n",
    "Understanding the concepts behind each statistical model is an important element of studying ML. However, Scikit-learn appears to the user as a mystical black box. The Naive Bayes method is easy to learn and fun to use. It will be presented in Python and applied to the Dataset.\r\n",
    "\r\n",
    "![Naive Bayes Classifier](Assets/NBC.jfif)\r\n",
    "\r\n",
    "## What is Bayes Theorem?\r\n",
    "\r\n",
    "The Bayes theorem is a mathematical formula to calculate conditional probability, named after 18th-century British mathematician Thomas Bayes. The possibility of an outcome occurring based on the likelihood of a preceding outcome occurring is known as conditional probability. Given fresh or more facts, Bayes' theorem can be used to alter previous forecasts or theories (update probability). Bayes' theorem is used in finance to assess the risk of lending money to prospective investors.\r\n",
    "\r\n",
    "\r\n",
    "The Bayes theorem, commonly known as Bayes' Rule or Bayes' Law, is the cornerstone of Bayesian statistics.\r\n",
    "\r\n",
    "It expresses the likelihood of an event based on past knowledge of circumstances that may be relevant to the event. Given that ( x ) has occurred, we may calculate the likelihood of ( y ) occurring using Bayes theory. The evidence ( x ) is the evidence, the previous experience ( y ) is the prior knowledge, and the likelihood ( P(x|y)) is the likelihood. The predictor variables are assumed to be independent in this case.\r\n",
    "\r\n",
    "It's equation is as follows:\r\n",
    "\r\n",
    "\\\\( P(y|x)= \\dfrac{P(x|y)P(y)}{P(x)} \\\\)\r\n",
    "where, \r\n",
    "* \\\\( y,x \\\\) = Events\r\n",
    "* \\\\( P(y|x) \\\\) = Probability of \\\\( y \\\\) given \\\\( x \\\\)\r\n",
    "* \\\\( P(x|y) \\\\) = Probability of \\\\( x \\\\) given \\\\( y \\\\)\r\n",
    "* \\\\( P(y), P(x) \\\\) = Independent probabilities of \\\\( y \\\\) and \\\\( x \\\\)\r\n",
    "\r\n",
    "The Naive Bayes Methods are a series of supervised learning algorithms based on Bayes' theorem and the \"naive\" assumption of conditional independence between every pair of features given the class variable's value.\r\n",
    "\r\n",
    "The variable ( y ) in our example is the class variable (Survival 0 or 1), which indicates whether a passenger would survive or not under the circumstances. The parameters/features are represented by the variable ( X ). ( X ) is written as ( X=(x 1, x 2,..., x n) ) and can be mapped to Age, Class, Sex, and so on. We get by inserting for ( X) in the Bayes Rule and expanding with the chain rule.\r\n",
    "        \r\n",
    "\\\\( P(y|x_{1}, x_{2}, ..., x_{n})= \\dfrac{P(x_{1}|y)P(x_{2}|y)...P(x_{n}|y)P(y)}{P(x_{1})P(x_{2})...P(x_{n})} \\\\)\r\n",
    "\r\n",
    "By examining the dataset, you can now compute the values for each likelihood and plug them into the equation. The class variable ( y ) has two possible outcomes in our case: 0 or 1. So, for each passenger, the survival chances for each situation of '*Survival*' or '*No survival*' (1 or 0, respectively) must be determined. The final outcome is the one with the highest likelihood. That is, the guy will survive if ( P(1) > P(0) ).\r\n"
   ],
   "metadata": {
    "papermill": {
     "duration": 0.016368,
     "end_time": "2021-09-27T19:07:37.240593",
     "exception": false,
     "start_time": "2021-09-27T19:07:37.224225",
     "status": "completed"
    },
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Lets import simple libraries"
   ],
   "metadata": {
    "papermill": {
     "duration": 0.014316,
     "end_time": "2021-09-27T19:07:37.270212",
     "exception": false,
     "start_time": "2021-09-27T19:07:37.255896",
     "status": "completed"
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import numpy as np\r\n",
    "import pandas as pd"
   ],
   "outputs": [],
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T19:07:37.312727Z",
     "iopub.status.busy": "2021-09-27T19:07:37.311976Z",
     "iopub.status.idle": "2021-09-27T19:07:37.316078Z",
     "shell.execute_reply": "2021-09-27T19:07:37.315404Z",
     "shell.execute_reply.started": "2021-09-27T19:06:55.752543Z"
    },
    "papermill": {
     "duration": 0.031331,
     "end_time": "2021-09-27T19:07:37.316269",
     "exception": false,
     "start_time": "2021-09-27T19:07:37.284938",
     "status": "completed"
    },
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here, instead of inbuilt libraries we will use custom functions to import and pre-process the data"
   ],
   "metadata": {
    "papermill": {
     "duration": 0.014351,
     "end_time": "2021-09-27T19:07:37.345599",
     "exception": false,
     "start_time": "2021-09-27T19:07:37.331248",
     "status": "completed"
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# Let's a CSV file\r\n",
    "def load_csv(filename):\r\n",
    "\tdataset = list()\r\n",
    "\twith open(filename, 'r') as file:\r\n",
    "\t\tcsv_reader = reader(file)\r\n",
    "\t\tfor row in csv_reader:\r\n",
    "\t\t\tif not row:\r\n",
    "\t\t\t\tcontinue\r\n",
    "\t\t\tdataset.append(row)\r\n",
    "\treturn dataset\r\n",
    " \r\n",
    "# Convert the target string column to float\r\n",
    "def str_column_to_float(dataset, column):\r\n",
    "\tfor row in dataset:\r\n",
    "\t\trow[column] = float(row[column].strip())\r\n",
    "\r\n",
    "def str_column_to_int(dataset, column):\r\n",
    "\tclass_values = [row[column] for row in dataset]\r\n",
    "\tunique = set(class_values)\r\n",
    "\tlookup = dict()\r\n",
    "\tfor i, value in enumerate(unique):\r\n",
    "\t\tlookup[value] = i\r\n",
    "\tfor row in dataset:\r\n",
    "\t\trow[column] = lookup[row[column]]\r\n",
    "\treturn lookup"
   ],
   "outputs": [],
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T19:07:37.379404Z",
     "iopub.status.busy": "2021-09-27T19:07:37.378733Z",
     "iopub.status.idle": "2021-09-27T19:07:37.386214Z",
     "shell.execute_reply": "2021-09-27T19:07:37.386699Z",
     "shell.execute_reply.started": "2021-09-27T19:06:55.765461Z"
    },
    "papermill": {
     "duration": 0.026302,
     "end_time": "2021-09-27T19:07:37.386883",
     "exception": false,
     "start_time": "2021-09-27T19:07:37.360581",
     "status": "completed"
    },
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here, we create a function to split the the in k-folds for train-test purpose and a function to calculate percentage accuracy"
   ],
   "metadata": {
    "papermill": {
     "duration": 0.014408,
     "end_time": "2021-09-27T19:07:37.416341",
     "exception": false,
     "start_time": "2021-09-27T19:07:37.401933",
     "status": "completed"
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# Split a dataset into k folds\r\n",
    "from random import randrange\r\n",
    "def cross_validation_split(dataset, n_folds):\r\n",
    "\tdataset_split = list()\r\n",
    "\tdataset_copy = list(dataset)\r\n",
    "\tfold_size = int(len(dataset) / n_folds)\r\n",
    "\tfor _ in range(n_folds):\r\n",
    "\t\tfold = list()\r\n",
    "\t\twhile len(fold) < fold_size:\r\n",
    "\t\t\tindex = randrange(len(dataset_copy))\r\n",
    "\t\t\tfold.append(dataset_copy.pop(index))\r\n",
    "\t\tdataset_split.append(fold)\r\n",
    "\treturn dataset_split\r\n",
    " \r\n",
    "# Calculate accuracy percentage\r\n",
    "def accuracy_metric(actual, predicted):\r\n",
    "\tcorrect = 0\r\n",
    "\tfor i in range(len(actual)):\r\n",
    "\t\tif actual[i] == predicted[i]:\r\n",
    "\t\t\tcorrect += 1\r\n",
    "\treturn correct / float(len(actual)) * 100.0"
   ],
   "outputs": [],
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T19:07:37.449752Z",
     "iopub.status.busy": "2021-09-27T19:07:37.449115Z",
     "iopub.status.idle": "2021-09-27T19:07:37.456662Z",
     "shell.execute_reply": "2021-09-27T19:07:37.457136Z",
     "shell.execute_reply.started": "2021-09-27T19:06:55.786370Z"
    },
    "papermill": {
     "duration": 0.026205,
     "end_time": "2021-09-27T19:07:37.457353",
     "exception": false,
     "start_time": "2021-09-27T19:07:37.431148",
     "status": "completed"
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# Evaluate an algorithm using a cross validation split\r\n",
    "def evaluate_algorithm(dataset, algorithm, n_folds, *args):\r\n",
    "\tfolds = cross_validation_split(dataset, n_folds)\r\n",
    "\tscores = list()\r\n",
    "\tfor fold in folds:\r\n",
    "\t\ttrain_set = list(folds)\r\n",
    "\t\ttrain_set.remove(fold)\r\n",
    "\t\ttrain_set = sum(train_set, [])\r\n",
    "\t\ttest_set = list()\r\n",
    "\t\tfor row in fold:\r\n",
    "\t\t\trow_copy = list(row)\r\n",
    "\t\t\ttest_set.append(row_copy)\r\n",
    "\t\t\trow_copy[-1] = None\r\n",
    "\t\tpredicted = algorithm(train_set, test_set, *args)\r\n",
    "\t\tactual = [row[-1] for row in fold]\r\n",
    "\t\taccuracy = accuracy_metric(actual, predicted)\r\n",
    "\t\tscores.append(accuracy)\r\n",
    "\treturn scores\r\n",
    " \r\n",
    "# Split the dataset by class values, returns a dictionary\r\n",
    "def separate_by_class(dataset):\r\n",
    "\tseparated = dict()\r\n",
    "\tfor i in range(len(dataset)):\r\n",
    "\t\tvector = dataset[i]\r\n",
    "\t\tclass_value = vector[-1]\r\n",
    "\t\tif (class_value not in separated):\r\n",
    "\t\t\tseparated[class_value] = list()\r\n",
    "\t\tseparated[class_value].append(vector)\r\n",
    "\treturn separated"
   ],
   "outputs": [],
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T19:07:37.496605Z",
     "iopub.status.busy": "2021-09-27T19:07:37.490793Z",
     "iopub.status.idle": "2021-09-27T19:07:37.501392Z",
     "shell.execute_reply": "2021-09-27T19:07:37.500720Z",
     "shell.execute_reply.started": "2021-09-27T19:06:55.805290Z"
    },
    "papermill": {
     "duration": 0.029079,
     "end_time": "2021-09-27T19:07:37.501543",
     "exception": false,
     "start_time": "2021-09-27T19:07:37.472464",
     "status": "completed"
    },
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Calculating the parameters like mean, standard deviation for further evaluation"
   ],
   "metadata": {
    "papermill": {
     "duration": 0.014634,
     "end_time": "2021-09-27T19:07:37.531384",
     "exception": false,
     "start_time": "2021-09-27T19:07:37.516750",
     "status": "completed"
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# Calculate the mean of a list of numbers\r\n",
    "def mean(numbers):\r\n",
    "\treturn sum(numbers)/float(len(numbers))\r\n",
    " \r\n",
    "# Calculate the standard deviation of a list of numbers\r\n",
    "def stdev(numbers):\r\n",
    "\tavg = mean(numbers)\r\n",
    "\tvariance = sum([(x-avg)**2 for x in numbers]) / float(len(numbers)-1)\r\n",
    "\treturn np.sqrt(variance)\r\n",
    " \r\n",
    "# Calculate the mean, stdev and count for each column in a dataset\r\n",
    "def summarize_dataset(dataset):\r\n",
    "\tsummaries = [(mean(column), stdev(column), len(column)) for column in zip(*dataset)]\r\n",
    "\tdel(summaries[-1])\r\n",
    "\treturn summaries\r\n",
    " \r\n",
    "# Split dataset by class then calculate statistics for each row\r\n",
    "def summarize_by_class(dataset):\r\n",
    "\tseparated = separate_by_class(dataset)\r\n",
    "\tsummaries = dict()\r\n",
    "\tfor class_value, rows in separated.items():\r\n",
    "\t\tsummaries[class_value] = summarize_dataset(rows)\r\n",
    "\treturn summaries\r\n",
    " \r\n",
    "# Calculate the Gaussian probability distribution function for x\r\n",
    "def calculate_probability(x, mean, stdev):\r\n",
    "\texponent = np.exp(-((x-mean)**2 / (2 * stdev**2 )))\r\n",
    "\treturn (1 / (np.sqrt(2 * np.pi) * stdev)) * exponent"
   ],
   "outputs": [],
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T19:07:37.574268Z",
     "iopub.status.busy": "2021-09-27T19:07:37.573398Z",
     "iopub.status.idle": "2021-09-27T19:07:37.576091Z",
     "shell.execute_reply": "2021-09-27T19:07:37.575573Z",
     "shell.execute_reply.started": "2021-09-27T19:06:55.823467Z"
    },
    "papermill": {
     "duration": 0.027844,
     "end_time": "2021-09-27T19:07:37.576260",
     "exception": false,
     "start_time": "2021-09-27T19:07:37.548416",
     "status": "completed"
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# Calculate the probabilities of predicting each class for a given row\r\n",
    "def calculate_class_probabilities(summaries, row):\r\n",
    "\ttotal_rows = sum([summaries[label][0][2] for label in summaries])\r\n",
    "\tprobabilities = dict()\r\n",
    "\tfor class_value, class_summaries in summaries.items():\r\n",
    "\t\tprobabilities[class_value] = summaries[class_value][0][2]/float(total_rows)\r\n",
    "\t\tfor i in range(len(class_summaries)):\r\n",
    "\t\t\tmean, stdev, _ = class_summaries[i]\r\n",
    "\t\t\tprobabilities[class_value] *= calculate_probability(row[i], mean, stdev)\r\n",
    "\treturn probabilities\r\n",
    " \r\n",
    "# Predict the class for a given row\r\n",
    "def predict(summaries, row):\r\n",
    "\tprobabilities = calculate_class_probabilities(summaries, row)\r\n",
    "\tbest_label, best_prob = None, -1\r\n",
    "\tfor class_value, probability in probabilities.items():\r\n",
    "\t\tif best_label is None or probability > best_prob:\r\n",
    "\t\t\tbest_prob = probability\r\n",
    "\t\t\tbest_label = class_value\r\n",
    "\treturn best_label"
   ],
   "outputs": [],
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T19:07:37.615965Z",
     "iopub.status.busy": "2021-09-27T19:07:37.615265Z",
     "iopub.status.idle": "2021-09-27T19:07:37.616662Z",
     "shell.execute_reply": "2021-09-27T19:07:37.617244Z",
     "shell.execute_reply.started": "2021-09-27T19:06:55.842397Z"
    },
    "papermill": {
     "duration": 0.026135,
     "end_time": "2021-09-27T19:07:37.617434",
     "exception": false,
     "start_time": "2021-09-27T19:07:37.591299",
     "status": "completed"
    },
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Defining the predict and naive bayes function"
   ],
   "metadata": {
    "papermill": {
     "duration": 0.014349,
     "end_time": "2021-09-27T19:07:37.646477",
     "exception": false,
     "start_time": "2021-09-27T19:07:37.632128",
     "status": "completed"
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# Naive Bayes Algorithm\r\n",
    "def naive_bayes(train, test):\r\n",
    "\tsummarize = summarize_by_class(train)\r\n",
    "\tpredictions = list()\r\n",
    "\tfor row in test:\r\n",
    "\t\toutput = predict(summarize, row)\r\n",
    "\t\tpredictions.append(output)\r\n",
    "\treturn(predictions)"
   ],
   "outputs": [],
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T19:07:37.682883Z",
     "iopub.status.busy": "2021-09-27T19:07:37.682168Z",
     "iopub.status.idle": "2021-09-27T19:07:37.683547Z",
     "shell.execute_reply": "2021-09-27T19:07:37.684138Z",
     "shell.execute_reply.started": "2021-09-27T19:06:55.857076Z"
    },
    "papermill": {
     "duration": 0.023133,
     "end_time": "2021-09-27T19:07:37.684366",
     "exception": false,
     "start_time": "2021-09-27T19:07:37.661233",
     "status": "completed"
    },
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![Species](Assets/iris-machinelearning.png)"
   ],
   "metadata": {
    "papermill": {
     "duration": 0.014353,
     "end_time": "2021-09-27T19:07:37.713701",
     "exception": false,
     "start_time": "2021-09-27T19:07:37.699348",
     "status": "completed"
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# Loading the dataset\r\n",
    "np.random.seed(1) \r\n",
    "from csv import reader\r\n",
    "dataset = load_csv(\"iris.csv\")"
   ],
   "outputs": [],
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T19:07:37.747136Z",
     "iopub.status.busy": "2021-09-27T19:07:37.746469Z",
     "iopub.status.idle": "2021-09-27T19:07:37.760773Z",
     "shell.execute_reply": "2021-09-27T19:07:37.760118Z",
     "shell.execute_reply.started": "2021-09-27T19:06:55.876648Z"
    },
    "papermill": {
     "duration": 0.032391,
     "end_time": "2021-09-27T19:07:37.760931",
     "exception": false,
     "start_time": "2021-09-27T19:07:37.728540",
     "status": "completed"
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# Viewing the dataset\r\n",
    "dataset_view = pd.DataFrame(dataset, columns =[\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\",\"species\"])\r\n",
    "dataset_view"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5</td>\n",
       "      <td>1.9</td>\n",
       "      <td>Virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2</td>\n",
       "      <td>Virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    sepal_length sepal_width petal_length petal_width    species\n",
       "0            5.1         3.5          1.4         0.2     Setosa\n",
       "1            4.9           3          1.4         0.2     Setosa\n",
       "2            4.7         3.2          1.3         0.2     Setosa\n",
       "3            4.6         3.1          1.5         0.2     Setosa\n",
       "4              5         3.6          1.4         0.2     Setosa\n",
       "..           ...         ...          ...         ...        ...\n",
       "145          6.7           3          5.2         2.3  Virginica\n",
       "146          6.3         2.5            5         1.9  Virginica\n",
       "147          6.5           3          5.2           2  Virginica\n",
       "148          6.2         3.4          5.4         2.3  Virginica\n",
       "149          5.9           3          5.1         1.8  Virginica\n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T19:07:37.807155Z",
     "iopub.status.busy": "2021-09-27T19:07:37.806419Z",
     "iopub.status.idle": "2021-09-27T19:07:37.824263Z",
     "shell.execute_reply": "2021-09-27T19:07:37.824788Z",
     "shell.execute_reply.started": "2021-09-27T19:06:55.894973Z"
    },
    "papermill": {
     "duration": 0.048645,
     "end_time": "2021-09-27T19:07:37.824982",
     "exception": false,
     "start_time": "2021-09-27T19:07:37.776337",
     "status": "completed"
    },
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "As we can see in the above dataset, we have **sepal_length** which is flower's sepel length, **sepal width** which is flower's sepel width, **petal length** which is flower's petal length and **petal width** which is flower's petal width and on the basis of \"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\" we are predicting the class \"species\" which is flower **species** consisting of 'Setosa', Virginica' and 'Versicolor' using Naive Bayes Classifier"
   ],
   "metadata": {
    "papermill": {
     "duration": 0.015129,
     "end_time": "2021-09-27T19:07:37.856017",
     "exception": false,
     "start_time": "2021-09-27T19:07:37.840888",
     "status": "completed"
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "# Test Naive Bayes on Iris Dataset\r\n",
    "for i in range(len(dataset[0])-1):\r\n",
    "\tstr_column_to_float(dataset, i)\r\n",
    "# convert class column to integers\r\n",
    "str_column_to_int(dataset, len(dataset[0])-1)\r\n",
    "# evaluate algorithm\r\n",
    "n_folds = 5\r\n",
    "scores = evaluate_algorithm(dataset, naive_bayes, n_folds)\r\n",
    "print('Mean Accuracy of Naive Bayes classifier is : %.3f%%' % (sum(scores)/float(len(scores))))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mean Accuracy of Naive Bayes classifier is : 95.333%\n"
     ]
    }
   ],
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-27T19:07:37.906844Z",
     "iopub.status.busy": "2021-09-27T19:07:37.906128Z",
     "iopub.status.idle": "2021-09-27T19:07:37.915256Z",
     "shell.execute_reply": "2021-09-27T19:07:37.915992Z",
     "shell.execute_reply.started": "2021-09-27T19:06:55.929682Z"
    },
    "papermill": {
     "duration": 0.044711,
     "end_time": "2021-09-27T19:07:37.916263",
     "exception": false,
     "start_time": "2021-09-27T19:07:37.871552",
     "status": "completed"
    },
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Advantages\n",
    "- It is not only a straightforward strategy, but also a quick and accurate one.\n",
    "- The calculation cost of Naive Bayes is quite low.\n",
    "- It can handle a large dataset with ease.\n",
    "- When compared to a continuous variable, it performs well with discrete response variables.\n",
    "- It can be used to solve problems involving numerous classes.\n",
    "- It also performs well when dealing with text analytics issues.\n",
    "- A Naive Bayes classifier outperforms other models like logistic regression when the assumption of independence is met."
   ],
   "metadata": {
    "papermill": {
     "duration": 0.019889,
     "end_time": "2021-09-27T19:07:37.955431",
     "exception": false,
     "start_time": "2021-09-27T19:07:37.935542",
     "status": "completed"
    },
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Disadvantages\n",
    "- The presumption of distinct characteristics. In practise, getting a group of predictors that are completely independent is nearly impossible.\n",
    "\n",
    "- When there is no training tuple for a specific class, the posterior probability is zero. The model is unable to provide predictions in this scenario. The Zero Likelihood Problem is the name for this problem."
   ],
   "metadata": {
    "papermill": {
     "duration": 0.01881,
     "end_time": "2021-09-27T19:07:37.992057",
     "exception": false,
     "start_time": "2021-09-27T19:07:37.973247",
     "status": "completed"
    },
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Conclusion\n",
    "\n",
    "Congratulations, we have successfully learnt using Naive Bayes without using any fancy libraries!\n",
    "\n",
    "Here, we learned about Naïve Bayes algorithm, it's working, Naive Bayes assumption, issues, implementation, advantages, and disadvantages. Along the road, you have also learned model building and evaluation without using scikit-learn for multinomial classes.\n",
    "\n",
    "Naive Bayes is the most straightforward and most potent algorithm. In spite of the significant advances of Machine Learning in the last couple of years, it has proved its worth. It has been successfully deployed in many applications from text analytics to recommendation engines."
   ],
   "metadata": {
    "papermill": {
     "duration": 0.023008,
     "end_time": "2021-09-27T19:07:38.036274",
     "exception": false,
     "start_time": "2021-09-27T19:07:38.013266",
     "status": "completed"
    },
    "tags": []
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 10.826877,
   "end_time": "2021-09-27T19:07:39.543346",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-09-27T19:07:28.716469",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}