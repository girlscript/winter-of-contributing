
## Supervised Machine Learning

2.1. What is Learning? Why Machine Learning works? (A+V+D)

2.2. Contrast between Regression and Classification (A+V+D)

2.3. Numpy Cheatsheet: Most Useful Functions and Methods (D)

2.4 Pandas Cheatsheet: Most Useful Functions and Methods (D)

2.5 Linear Regression (A+V+D)

2.6. Logistic Regression (A+V+D)

2.7. Contrast between Linear and Logistic Regression (A+V+D)
     - Do plotting and visually justify the contrast between both. How Logistic Regression attempts to fit better relative to Linear Regression.
     
2.8. K-Nearest Neighbour Algorithm (A+V+D)

2.9. Decision Trees (A+V+D)

2.10. Support Vector Machines (A+V+D)

2.11. Naive Bayes (A+V+D)

2.12. Implement Logistic Regression without using any standard ML library like scikit-learn or more.* (D)

2.13. Implement Naive Bayes without using any standard ML library like scikit-learn or more.* (D)

2.14. Implement SVM without using any standard ML library like scikit-learn or more.* (D)

2.15. Implement Decision Tree Agorithms without using any standard ML library like scikit-learn or more.* (D)

2.16. Implement KNN without using any standard ML library like scikit-learn or more.* (D)

2.17. Random Forest Algorithms (A+D+V)

2.18. Implement Random Forest without using any standard ML library like scikit-learn or more.* (D)

2.19. Gradient Descent Algorithms (A+D+V)

2.20. Implement Gradient Descent without using any standard ML library like scikit-learn or more.* (D)



**_N.B.: (*) marked issues can only be solved using Numpy/Pandas. No other libraries will be entertained!_**

*********************************************************
### ‚ùÑÔ∏è GWoC 2021
Happy Contributing üöÄ

