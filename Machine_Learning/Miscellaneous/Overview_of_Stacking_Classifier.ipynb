{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Stacking Classifier.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mk_B1JhMSbNv"
      },
      "source": [
        "In this Tutorial, we will look at understanding what is stacking and demonstrate how we can use Scikit-Learn library in order to simplify stacking pipelines and create interesting models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UvcGGcxxTSM3"
      },
      "source": [
        "# What is Stacking?\n",
        "Stacking is a strategy that takes the output of numerous regression or classification models and feeds it into a meta-classifier or regressor.\n",
        "Stacking, like Random Forests, is an ensemble learning strategy in which the quality of prediction is increased by mixing, often, weak models. </br>\n",
        "Stacking comes into play when we have numerous models capable of solving a particular problem in different ways each with its own pros and cons. It suggests to use another machine learning model that learns when to use or trust each model in the ensemble.\n",
        "\n",
        "# So How is stacking different from boosting and bagging?\n",
        "- Unlike bagging, the models in stacking are usually distinct (e.g., not all decision trees) and fit on the same dataset (e.g. instead of samples of the training dataset).\n",
        "- Unlike boosting, stacking uses a single model to learn how to integrate the predictions from the contributing models in the most effective way (e.g. instead of a sequence of models that correct the predictions of prior models).\n",
        "\n",
        "# Architecture of Stacking Models\n",
        "<img src=\"https://miro.medium.com/max/2000/1*XsTcX5N6FXQW1bGhS9hxJQ.png\" />\n",
        "Image Credits : https://towardsdatascience.com/stacking-made-easy-with-sklearn-e27a0793c92b\n",
        "\n",
        "A stacking model's architecture consists of two or more base models, also known as level-0 models, and a meta-model that combines the predictions of the base models, also known as a level-1 model.\n",
        "\n",
        "Models that are fitted to the training data and whose predictions are compiled are known as Level-0 Models (Base-Models).\n",
        "Level-1 Model (Meta-Model) is a model that learns how to combine the predictions of the basic models in the most effective way possible.\n",
        "\n",
        "The most typical method for producing the training dataset for the meta-model is k-fold cross-validation of the base models, with the out-of-fold predictions serving as the foundation for the meta-training model's dataset.\n",
        "\n",
        "The inputs to the base models, such as inputsÂ of the training data, may also be included in the meta-training model's data. This can give the meta-model more context in terms of how to best combine the meta-predictions. model's\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHe0eJBOYHhx"
      },
      "source": [
        "Now Let's look at how we can implement stacking using scikit learn library.\n",
        "I will be using make_classification() function to create a synthetic binary classification problem with 1,000 examples and 20 input features. We will generate a Madelon-like synthetic data set using Scikit-learn for a classification task. To find out more about the implementation of dataset please visit [here](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DgDOVnqQSAIX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6199a454-7b7f-4284-f03d-99bb5d9162ae"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "# test classification dataset\n",
        "from sklearn.datasets import make_classification\n",
        "# define dataset\n",
        "X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=1)\n",
        "# summarize the dataset\n",
        "print(X.shape, y.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1000, 20) (1000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5MpDX5c2cZUr"
      },
      "source": [
        "Let's implement the classification using SVC, Naive Bayes, KNN , Decision Tree Classsifier and Logistic Regression individually and look at their accuracy first."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1IZ4VfWb3ka"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 1000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KpTVQK9Yen7n",
        "outputId": "ceab1ebb-89d1-4222-a1ad-5d03adaa9923"
      },
      "source": [
        "######## Logistic Regression\n",
        "clf_lr = LogisticRegression()\n",
        "print(\"The Accuracy obtained from Linear Regression is: \")\n",
        "clf_lr.fit(X_train, y_train).score(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Accuracy obtained from Linear Regression is: \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.89"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kSeDpP9tfThT",
        "outputId": "1b6e92e7-e8eb-4a80-ac27-b7f26acee812"
      },
      "source": [
        "######## SVC\n",
        "clf_svc = SVC()\n",
        "print(\"The Accuracy obtained from SVC is: \")\n",
        "clf_svc.fit(X_train, y_train).score(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Accuracy obtained from SVC is: \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.96"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fVOCiQb1fj0P",
        "outputId": "d990b615-3605-44af-f8d1-1711142a2c03"
      },
      "source": [
        "######## Naive Bayes\n",
        "clf_nb = GaussianNB()\n",
        "print(\"The Accuracy obtained from Naive Bayes is: \")\n",
        "clf_nb.fit(X_train, y_train).score(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Accuracy obtained from Naive Bayes is: \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.87"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y8llmRIAfwTW",
        "outputId": "9c3b1cb3-a43d-460e-b6e1-7121d19d71ef"
      },
      "source": [
        "######## Decision Tree Classifier\n",
        "clf_dtc = DecisionTreeClassifier()\n",
        "print(\"The Accuracy obtained from Decision Tree Classifier is: \")\n",
        "clf_dtc.fit(X_train, y_train).score(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Accuracy obtained from Decision Tree Classifier is: \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.83"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36W_QXdPqMHH",
        "outputId": "5b018f5d-05ca-4143-a498-65528f7056be"
      },
      "source": [
        "######## KNN\n",
        "clf_knn = KNeighborsClassifier()\n",
        "print(\"The Accuracy obtained from KNN is: \")\n",
        "clf_knn.fit(X_train, y_train).score(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Accuracy obtained from KNN is: \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.93"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2We2mz1LgWFS"
      },
      "source": [
        "We can see that in this case, SVC performs the best with about 96 percent accuracy score.\n",
        "\n",
        "Now let's implement stacking. Our expectation is that the stacking ensemble will perform better than any single base model.\n",
        "\n",
        "This is not always the case and if it is not the case, then the base model should be used in favor of the ensemble model.\n",
        "\n",
        "We use Naive Bayes, SVC, Decision Tree Classifier, KNN as our base learners in the order specified respectively and logistic Regression as our meta learner."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RjUrweegRGy"
      },
      "source": [
        "from sklearn.ensemble import StackingClassifier\n",
        "\n",
        "# Create Base Learners\n",
        "base_learners = [\n",
        "                 ('clf_1', clf_nb),\n",
        "                 ('clf_2', clf_svc),\n",
        "                 ('clf_3', clf_dtc),\n",
        "                 ('clf_4', clf_knn),          \n",
        "                ]\n",
        "\n",
        "# Initialize Stacking Classifier with the Meta Learner\n",
        "stacking_clf = StackingClassifier(estimators=base_learners, final_estimator=clf_lr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJE6Ps3AjCTp",
        "outputId": "50e99152-19c9-4223-d5bc-56089ffe858a"
      },
      "source": [
        "print(\"The Accuracy obtained from stacking classifiers is: \")\n",
        "stacking_clf.fit(X_train, y_train).score(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Accuracy obtained from stacking classifiers is: \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.965"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "VcIfL95zS3XD",
        "outputId": "17ba5f4f-76cf-4a02-eb81-568415fba5c0"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        " \n",
        "# Figure Size\n",
        "fig = plt.figure(figsize =(10, 7))\n",
        " \n",
        "# Horizontal Bar Plot\n",
        "plt.bar(['Logistic Regression', 'SVC', 'Naive Bayes', 'Decision Tree', 'KNN', 'Stacking'], [0.89,0.96,0.87,0.83,0.93,0.965])\n",
        " \n",
        "# Show Plot\n",
        "plt.show()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9tjMx5Z4qsjP"
      },
      "source": [
        "In this case, we can see that the stacking ensemble appears to perform better than any single model on average, achieving an accuracy of about 96.5 percent."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_Fk3VACsDh-"
      },
      "source": [
        "## Conclusion\n",
        "Stacking is intended to improve modelling performance, although it is not guaranteed to do so in all situations.\n",
        "\n",
        "Achieving an improvement in performance depends on the complexity of the problem and whether it is sufficiently well represented by the training data and complex enough that there is more to learn by combining predictions. It also depends on the underlying models chosen and whether or not they are sufficiently skillful and uncorrelated in their predictions (or errors).\n",
        "\n",
        "Given its lesser complexity (e.g., it's easier to define, train, and maintain), the base model should be used instead of the stacking ensemble if it performs as well as or better than the stacking ensemble."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jzUQA4E1sl1d"
      },
      "source": [
        "## References\n",
        "- https://machinelearningmastery.com/stacking-ensemble-machine-learning-with-python/\n",
        "- https://towardsdatascience.com/stacking-classifiers-for-higher-predictive-performance-566f963e4840"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ULhIJYYsywy"
      },
      "source": [
        "## Contributed By:\n",
        "Nikita Bhrugumaharshi Emberi </br>\n",
        "Domain-Machine Learning </br>\n",
        "Batch-6 </br>\n",
        "Serial No-992 </br>\n",
        "[@NikitaEmberi](https://github.com/NikitaEmberi)"
      ]
    }
  ]
}