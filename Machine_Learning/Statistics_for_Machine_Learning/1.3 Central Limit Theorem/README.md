# Central Limit Theorem

## Defination 
The Central Limit Theorm is a statistical theory which states that given a large sample size from a dataset with a finite level of varience, the mean of all samples from the same dataset will be approximately equal to the mean of the dataset. It uses sampling distribution to generalize the samples and use to calculate approx mean, standard daviation and other important parameters.

In a nutshell central limit theorem can also be defined as, The distribution of mean values of a not normal distribution is close to normal. 

## Formula
The mean of the sample means is denoted as:

            µ X̄ = µ
            
    where,
       µ X̄ = Mean of the sample means
       µ= Population mean

And, the standard deviation of the sample mean is denoted as:

            σ X̄ = σ/sqrt(n)
    where,
       σ X̄ = Standard deviation of the sample mean
       σ = Population standard deviation
       n = sample size
 
 ## Significance 
 If N is increased, the spread of the distribution increases and it becomes more normal.
 
 ![alt text](https://github.com/prishita-s/winter-of-contributing/blob/main/Machine_Learning/Statistics_for_Machine_Learning/Assets/img1.jpg)
 
 If we increase the samples drawn from the population, the standard deviation of sample means will decrease. This helps us estimate the population mean much more accurately
 

### Practical Applications 
  - To calculate the mean income of a particular region
 - Political elections: here it is used to estimate the percentage of people who support a particular candidate  

## Example of Implementing CLT
[Click here](https://github.com/prishita-s/winter-of-contributing/blob/main/Machine_Learning/Statistics_for_Machine_Learning/1.3%20Central%20Limit%20Theorem/1_3_Central_Limit_Theorem_(D).ipynb) to check out a sample code where CLT is demonstrated. 
